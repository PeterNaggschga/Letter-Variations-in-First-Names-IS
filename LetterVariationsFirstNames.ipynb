{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterNaggschga/Letter-Variations-in-First-Names-IS/blob/main/LetterVariationsFirstNames.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RadixTree\n",
        "Implementation eines RadixTrees."
      ],
      "metadata": {
        "id": "sjY2oRI3_jVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RadixTree:\n",
        "    \"\"\"contains a dict, which links to multiple RadixTree's. The key to another tree is a str and\n",
        "    if a transition ends in a word, the isWord-variable is True\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, isWord=False, transitions=None):\n",
        "        if transitions is None:\n",
        "            transitions = dict()\n",
        "        self.isWord = isWord\n",
        "        self.transitions = transitions\n",
        "\n",
        "    def insertWord(self, word):\n",
        "        \"\"\"inserts a word into the tree\n",
        "\n",
        "        Args:\n",
        "            word (str): is the str, that gets inserted\n",
        "        \"\"\"\n",
        "        for i in range(0, len(word)):\n",
        "            # goes through 'tobi' with 'tobi', 'tob', 'to', 't'\n",
        "            possibleTransition = word[:len(word) - i]\n",
        "            if self.transitions.get(possibleTransition) is not None:\n",
        "                child = self.transitions.get(possibleTransition)\n",
        "                if possibleTransition == word:\n",
        "                    child.isWord = True\n",
        "                else:\n",
        "                    child.insertWord(word[len(possibleTransition):])\n",
        "                return\n",
        "\n",
        "            for key in self.transitions.keys():\n",
        "                if possibleTransition == key[:len(possibleTransition)]:\n",
        "                    child = self.transitions.pop(key)\n",
        "                    newDict = dict()\n",
        "                    newDict[key[len(possibleTransition):]] = child\n",
        "                    self.transitions[possibleTransition] = RadixTree(possibleTransition == word, newDict)\n",
        "                    if possibleTransition != word:\n",
        "                        self.transitions[possibleTransition].insertWord(word[len(possibleTransition):])\n",
        "                    return\n",
        "\n",
        "        self.transitions[word] = RadixTree(True, dict())\n",
        "\n",
        "    def __strRecursive__(self, timesOfIndentation, lengthOfTransitionString):\n",
        "        result = \"\"\n",
        "        if self.isWord:\n",
        "            result += \".\"\n",
        "        keys = list(self.transitions.keys())\n",
        "        keys.sort()\n",
        "        for key in keys:\n",
        "            recursiveResult = self.transitions[key].__strRecursive__(timesOfIndentation + lengthOfTransitionString,\n",
        "                                                                     len(key))\n",
        "            result += \"\\n\" + (timesOfIndentation + lengthOfTransitionString) * \"_\" + key + recursiveResult\n",
        "        return result\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"generates a readable str, containing all class variables (the tree).\n",
        "\n",
        "        Returns:\n",
        "            str: the generated str\n",
        "        \"\"\"\n",
        "        return self.__strRecursive__(0, 0)\n",
        "\n",
        "    def getSimilarWordsOfSameLength(self, maximumDifferentLetters, word):\n",
        "        \"\"\"compares the given word with entries of the same length. Returns all of them with less or equal different letters than with maximumDifferentLetters described\n",
        "\n",
        "        Args:\n",
        "            maximumDifferentLetters (int): limits the amount of accepted different letters when comparing 2 words\n",
        "            word (str): the given word\n",
        "\n",
        "        Returns:\n",
        "            list: returns a list of similar words with the same length. Does contain itself\n",
        "        \"\"\"\n",
        "        if word == \"\":\n",
        "            return [word] if self.isWord else []\n",
        "\n",
        "        resultList = list()\n",
        "        for key in self.transitions.keys():\n",
        "            if len(key) > len(word):\n",
        "                continue\n",
        "            differences = 0\n",
        "            for i in range(0, len(key)):\n",
        "                differences += word[i] != key[i]\n",
        "                if differences > maximumDifferentLetters:\n",
        "                    break\n",
        "\n",
        "            if differences > maximumDifferentLetters:\n",
        "                continue\n",
        "            resultTmp = self.transitions[key].getSimilarWordsOfSameLength(maximumDifferentLetters - differences,\n",
        "                                                                          word[len(key):])\n",
        "            if resultTmp:\n",
        "                resultList.extend([key + tmp for tmp in resultTmp])\n",
        "        return resultList\n"
      ],
      "metadata": {
        "id": "dYT__cinAe6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RadixTreesByWordLength\n",
        "Ein Container, der Wörter je nach Länge in unterschiedliche RadixTrees ablegt und ansonsten wie ein Tree agiert."
      ],
      "metadata": {
        "id": "Gs-NXTuf_kfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RadixTreesByWordLength:\n",
        "    \"\"\"contains a dict, which links to multiple RadixTree's, each storing words of the same length\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.radixTrees = dict()\n",
        "\n",
        "    def insertWord(self, word):\n",
        "        \"\"\"inserts a word into the tree\n",
        "\n",
        "        Args:\n",
        "            word (str): is the str, that gets inserted\n",
        "        \"\"\"\n",
        "        length = len(word)\n",
        "        if self.radixTrees.get(length) is None:\n",
        "            self.radixTrees[length] = RadixTree()\n",
        "        self.radixTrees[length].insertWord(word)\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"generates a readable str, containing all class variables (the tree)\n",
        "\n",
        "        Returns:\n",
        "            str: the generated str\n",
        "        \"\"\"\n",
        "        tmp = \"\"\n",
        "        lengthStr = self.radixTrees.keys()\n",
        "        sortedLengths = [int(lengths) for lengths in lengthStr]\n",
        "        sortedLengths.sort()\n",
        "\n",
        "        for length in sortedLengths:\n",
        "            tmp += \"RadixTree with words of length \" + str(length) + \":\"\n",
        "            tmp += self.radixTrees[length].__str__()\n",
        "            tmp += \"\\n\"\n",
        "        return tmp\n",
        "\n",
        "    def getSimilarWordsOfSameLength(self, maximumDifferentLetters, word):\n",
        "        \"\"\"compares the given word with entries of the same length. Returns all of them with less or equal different letters than with maximumDifferentLetters described\n",
        "\n",
        "        Args:\n",
        "            maximumDifferentLetters (int): limits the amount of accepted different letters when comparing 2 words\n",
        "            word (str): the given word\n",
        "\n",
        "        Returns:\n",
        "            list: returns a list of similar words with the same length. Does contain itself\n",
        "        \"\"\"\n",
        "        length = len(word)\n",
        "        if self.radixTrees.get(length) is None:\n",
        "            return []\n",
        "        return self.radixTrees[length].getSimilarWordsOfSameLength(maximumDifferentLetters, word)\n"
      ],
      "metadata": {
        "id": "mIsL8VDqBM5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SubstituitionMatrix\n",
        "Implementation einer BLOSUM-Substitutionsmatrix."
      ],
      "metadata": {
        "id": "SxfUiN4P_k7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SubstitutionMatrix:\n",
        "    \"\"\"Stores letter-variations as a matrix. The matrix is a dict linking the first letter to a second dict, linking the second letter to its occurrence (int)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.letters = [\n",
        "            'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u',\n",
        "            'v', 'w', 'x', 'y', 'z']\n",
        "        self.matrix = dict()\n",
        "        matrixTmp = dict()\n",
        "        for letter in self.letters:\n",
        "            self.matrix[letter] = dict()\n",
        "            matrixTmp[letter] = 0\n",
        "        for letter in self.letters:\n",
        "            self.matrix[letter] = matrixTmp.copy()\n",
        "        self.totalLetterTransitions = 0\n",
        "\n",
        "    def addLetterTransition(self, fr, to):\n",
        "        \"\"\"adds the transistion from one letter to another in the matrix\n",
        "\n",
        "        Args:\n",
        "            fr (str): a single lower character of the alphabet\n",
        "            to (str): a second single lower character of the alphabet\n",
        "\n",
        "        Returns:\n",
        "            bool: is False if one of the characters was not accepted, True if both were accepted\n",
        "        \"\"\"\n",
        "        if fr not in self.letters or to not in self.letters:\n",
        "            return False\n",
        "\n",
        "        self.matrix[fr][to] += 1\n",
        "        self.totalLetterTransitions += 1\n",
        "        return True\n",
        "\n",
        "    def getMatrixEntryInPercent(self, fr, to):\n",
        "        \"\"\"returns a specific matrix-entry in %\n",
        "\n",
        "        Args:\n",
        "            fr (str): a single lower character of the alphabet\n",
        "            to (str): a second single lower character of the alphabet\n",
        "\n",
        "        Returns:\n",
        "            float: returns -1.0 if one of the given str's was not accepted, the matrix-entry in percent otherwise\n",
        "        \"\"\"\n",
        "        if fr not in self.letters or to not in self.letters:\n",
        "            return -1.0\n",
        "\n",
        "        if self.totalLetterTransitions == 0:\n",
        "            return 0.0\n",
        "        return (self.matrix[fr][to] / self.totalLetterTransitions) * 100\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"generates a readable str for the matrix\n",
        "\n",
        "        Returns:\n",
        "            str: the generated str\n",
        "        \"\"\"\n",
        "\n",
        "        tmp = \"Substitutionmatrix in %:\\n\"\n",
        "        for to in self.matrix.keys():\n",
        "            tmp += \"\\t\" + to\n",
        "        tmp += \"\\n\"\n",
        "        \n",
        "        for fr in self.letters:\n",
        "            tmp += fr\n",
        "            for to in self.letters:\n",
        "                strEntry = str(self.getMatrixEntryInPercent(fr, to))\n",
        "                if len(strEntry) < 4:\n",
        "                    strEntry = (4 - len(strEntry)) * \"0\" + strEntry\n",
        "                tmp += \"\\t\" + strEntry[:4]\n",
        "            tmp += \"\\n\"\n",
        "        return tmp\n",
        "\n",
        "    def addLetterVariationsToMatrix(self, name, similarNames):\n",
        "        \"\"\"retrieves differences of names with the original and inserts these letter-variations into the substitution-matrix\n",
        "\n",
        "        Args:\n",
        "            name (str): is the original name\n",
        "            similarNames (list): list of similar names as str's\n",
        "        \"\"\"\n",
        "        for similarName in similarNames:\n",
        "            for i in range(len(name)):\n",
        "                if name[i] != similarName[i]:\n",
        "                    self.addLetterTransition(name[i], similarName[i])\n",
        "                    \n",
        "\n",
        "    # here is a simple way of storing and retrieveing the matrix in an external file\n",
        "    \"\"\"\n",
        "    def save(self):\n",
        "        f = open(\"backupFiles/SubstitutionMatrix.txt\", \"w\")\n",
        "        tmp = str(self.totalLetterTransitions) + \";\"\n",
        "        for key1 in self.matrix.keys():\n",
        "            tmp += str(key1) + \":\"\n",
        "            for key2 in self.matrix[key1]:\n",
        "                tmp += str(key2) + \"-\" + str(self.matrix[key1][key2]) + \",\"\n",
        "            tmp = tmp[:-1] + \"\\n\"\n",
        "        f.write(tmp[:-1])\n",
        "        f.close()\n",
        "        \n",
        "    def loadBackup(self):\n",
        "        f = open(\"backupFiles/SubstitutionMatrix.txt\", \"r\")\n",
        "        backup = (f.read()).split(';')\n",
        "        self.totalLetterTransitions = int(backup[0])\n",
        "        backup = backup[1].split(\"\\n\")\n",
        "        for entryStr in backup:\n",
        "            key1 = entryStr[0]\n",
        "            for entry in entryStr[2:].split(','):\n",
        "                key2 = entry[0]\n",
        "                self.matrix[key1][key2] = int(entry[2:])\n",
        "        f.close()\n",
        "    \"\"\"\n"
      ],
      "metadata": {
        "id": "bWIfBEgBB9Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo\n",
        "Extraktion der Variationen in Vornamen."
      ],
      "metadata": {
        "id": "3CyZwWA7CEVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import re\n",
        "# install and import Entrez and Medline first\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "try:\n",
        "    from Bio import Entrez, Medline\n",
        "except:\n",
        "    # One of these 2 lines should work\n",
        "    # !pip install Bio\n",
        "    install('Bio')\n",
        "from Bio import Entrez, Medline\n",
        "\n",
        "\n",
        "def getPapers(myQuery, maxPapers, myEmail=\"freytag64@gmail.com\"):\n",
        "    \"\"\"retrieves some Papers from Pubmed\n",
        "\n",
        "    Args:\n",
        "        myQuery (str): is the given Query \n",
        "        maxPapers (int): is a limit of the number of papers, which will be retrieved\n",
        "        myEmail (str, optional): an email. Defaults to \"freytag64@gmail.com\".\n",
        "\n",
        "    Returns:\n",
        "        list: papers as list of dictionarys containing abstract, authors, ...\n",
        "    \"\"\"\n",
        "    # Get articles from PubMed\n",
        "    Entrez.email = myEmail\n",
        "    record = Entrez.read(Entrez.esearch(db=\"pubmed\", term=myQuery, retmax=maxPapers))\n",
        "    idlist = record[\"IdList\"]\n",
        "    print(\"\\nThere are %d records for %s.\" % (len(idlist), myQuery.strip()))\n",
        "    records = Medline.parse(Entrez.efetch(db=\"pubmed\", id=idlist, rettype=\"medline\", retmode=\"text\"))\n",
        "    return list(records)\n",
        "\n",
        "\n",
        "def retrieveAllFirstNames(records):\n",
        "    \"\"\"takes list of papers (each is a dict) and extracts the first names as a combined list with a regular expression \n",
        "\n",
        "    Args:\n",
        "        records (list): list of papers\n",
        "\n",
        "    Returns:\n",
        "        list: list of first names as str's\n",
        "    \"\"\"\n",
        "    # retrieves first names from authors with regular expressions\n",
        "    firstNameList = list()\n",
        "    for record in filter(lambda x: 'FAU' in x, records):\n",
        "        for fullName in record['FAU']:\n",
        "            # since names are formatted like 'Lastname, Firstnames', split by ',' to get Firstnames\n",
        "            firstName = fullName.split(',')[1].strip()\n",
        "            names1 = list(filter(lambda x: len(x) > 1, firstName.split()))\n",
        "            firstNameList.extend(names1)\n",
        "            # print(fullName + \" --> \" + str(names1))\n",
        "            \n",
        "            # fixed: does not get name-pairs like \"le Roux, Marlene F\", since the lastname 'Roux' starts with ' ' too\n",
        "            # fixed (see comment): does not really get name-pairs like \"Something, A Mohammed\", since A is just a single letter (it ignores A as a firstname)\n",
        "            # a better one can be generated by using Multiple Sequence Alignment from the lectures. Names like Al-Abehd with '-' are just added as 'Al-Abehd' too.\n",
        "            # sometimes accepts stuff like 'jr'\n",
        "            \n",
        "            \"\"\"\n",
        "            expression = r' ([a-zA-Z_-][a-zA-Z_-]+)'\n",
        "            names2 = re.findall(expression, fullName)\n",
        "            # firstNameList.extend(names2)            \n",
        "            \n",
        "            if names1 != names2:\n",
        "              print(fullName + \" --> \" + str(names1))\n",
        "              print(fullName + \" --> \" + str(names2))\n",
        "            \"\"\"\n",
        "\n",
        "    return firstNameList\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    maxPapers = 0  # limit the number of papers retrieved\n",
        "\n",
        "    matrix = SubstitutionMatrix()  # saves letter-transitions in a matrix\n",
        "\n",
        "    myQuery = \"(\\\"2021/01/20\\\"[Date - Publication] : \\\"2021/01/20\\\"[Date - Publication])\"\n",
        "    records = getPapers(myQuery, maxPapers)\n"
      ],
      "metadata": {
        "id": "t3WAzxEOCKvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clustering\n",
        "Clustern der Namen mit einer DBSCAN-ähnlichen Methode.\n",
        "\n",
        "Unterschiede:\n",
        "- zu große Cluster werden strenger erneut geclustert (maximale Größe: 1000 Namen)\n",
        "- beim Prüfen, ob ein Knoten ein Kernknoten ist, zählen bereits erkundete Knoten nicht mehr\n",
        "- Namen mit Länge 2 oder kürzer werden ignoriert\n",
        "\n",
        "Ein Kernknoten braucht mindestens 6 unbesuchte Nachbarn um als Kernknoten zu gelten.\n",
        "\n",
        "Eliminiert nicht erreichbare Knoten.\n",
        "\n",
        "Knoten: einzelne Namen\n",
        "\n",
        "Knotenübergänge (ungerichtet) zwischen Namen gleicher Länge mit maximaler Hamming-Distanz 1"
      ],
      "metadata": {
        "id": "mFkZHyruSPEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getNames() -> list:\n",
        "    \"\"\"reads names from external file (removes duplicates)\n",
        "\n",
        "    Returns:\n",
        "        list: list of firstnames\n",
        "    \"\"\"\n",
        "    print(\"reads in names from external list\")\n",
        "    names = list()\n",
        "    with open(\"2022FirstNames\", \"r\") as myfile:\n",
        "        try:\n",
        "            names = list(set(myfile.read().split()))\n",
        "        finally:\n",
        "            myfile.close()\n",
        "\n",
        "    print(\"names in total: \" + str(len(names)))\n",
        "    \n",
        "    return names\n",
        "\n",
        "def getClusters() -> list:\n",
        "    \"\"\"reads in clusters from external file\n",
        "\n",
        "    Returns:\n",
        "        list: is list of clusters (list of names)\n",
        "    \"\"\"\n",
        "    print(\"reads in clusters from external list\")\n",
        "    clusters = list()\n",
        "    with open(\"clusteredNames\", \"r\") as myfile:\n",
        "        try:\n",
        "            clusterAsStrings = myfile.read().split(\"\\n\")\n",
        "            for string in clusterAsStrings:\n",
        "                clusters.append(string.split())\n",
        "        finally:\n",
        "            myfile.close()\n",
        "\n",
        "    print(\"clusters in total: \" + str(len(clusters)))\n",
        "    \n",
        "    return clusters\n",
        "    \n",
        "\n",
        "def Dbscan(names : list, min_samples : int, min_word_length : int, max_cluster_length : int) -> list:\n",
        "    \"\"\"clusters list of names with DBSCAN\n",
        "\n",
        "    Args:\n",
        "        names (list): list of names\n",
        "        min_samples (int): the number of samples in a neighborhood for a point to be considered a core point\n",
        "        min_word_length (int): only words with this length or longer are clustered\n",
        "        max_cluster_length (int): maximum size of cluster. If found cluster are bigger, they will devided\n",
        "    Returns:\n",
        "        list: list of clusters (each cluster is a list of names)\n",
        "    \"\"\"\n",
        "    \n",
        "    tree = RadixTreesByWordLength()\n",
        "    clusters = list()\n",
        "    names = list(filter(lambda x : len(x) >= min_word_length, names))\n",
        "    names.sort(reverse=True)\n",
        "    \n",
        "    tmp = list()\n",
        "    for n in names:\n",
        "        tmp.append(n.lower())\n",
        "    names = tmp\n",
        "    \n",
        "    #construct the RadixTree\n",
        "    for n in names:\n",
        "        tree.insertWord(n)\n",
        "    \n",
        "    #clustering\n",
        "    while len(names) > 0:\n",
        "        name = names.pop()\n",
        "        cluster = set()\n",
        "        stack = [name]\n",
        "        \n",
        "        #fill cluster\n",
        "        while len(stack) > 0:\n",
        "            node = stack.pop()\n",
        "            \n",
        "            #check if name is a core-sample\n",
        "            neighbors = tree.getSimilarWordsOfSameLength(1, node)\n",
        "            #already found nodes are not considered as neighbors\n",
        "            toBeRemoved = list()\n",
        "            for n in neighbors:\n",
        "                if n in cluster:\n",
        "                    toBeRemoved.append(n)\n",
        "                    continue\n",
        "                for c in clusters:\n",
        "                    if n in c:\n",
        "                        toBeRemoved.append(n)\n",
        "            for n in toBeRemoved:\n",
        "                neighbors.remove(n) \n",
        "                \n",
        "            #add new names to cluster\n",
        "            if len(neighbors) >= min_samples:\n",
        "                for n in filter(lambda x : x in names, neighbors):\n",
        "                    names.remove(n)\n",
        "                stack.extend(neighbors)\n",
        "                cluster.update(set(neighbors))\n",
        "        \n",
        "        cluster = list(cluster)\n",
        "        #add filled cluster\n",
        "        if len(cluster) > 1 and len(cluster) <= max_cluster_length:\n",
        "            clusters.append(cluster)\n",
        "        #if a cluster is too big, cluster it again\n",
        "        elif len(cluster) > max_cluster_length:\n",
        "            smallerClusters = Dbscan(cluster, min_samples + 5, min_word_length, max_cluster_length)\n",
        "            clusters.extend(smallerClusters)    \n",
        "\n",
        "    return clusters\n",
        "            "
      ],
      "metadata": {
        "id": "_mjXEEIbUC_L"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names = getNames()\n",
        "\n",
        "print(\"clustering (takes a while):\")\n",
        "clusters = Dbscan(names, 6, 3, 1000)\n",
        "\n",
        "print(str(len(clusters)) + \" different clusters\")\n",
        "i = 0\n",
        "for c in clusters:\n",
        "    i += len(c)\n",
        "print(str(i) + \" names clustered\")\n",
        "\n",
        "#save in file\n",
        "with open(\"clusteredNames\", \"w+\") as myfile:\n",
        "    try:\n",
        "        tmp = \"\"\n",
        "        for cluster in clusters:\n",
        "            for name in cluster:\n",
        "                tmp += name + \" \"\n",
        "            tmp += \"\\n\"\n",
        "        myfile.write(tmp)\n",
        "    finally:\n",
        "        myfile.close()"
      ],
      "metadata": {
        "id": "VOBIPmEGVDUA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}