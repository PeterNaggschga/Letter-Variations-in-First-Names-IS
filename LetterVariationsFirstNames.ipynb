{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterNaggschga/Letter-Variations-in-First-Names-IS/blob/main/LetterVariationsFirstNames.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RadixTree\n",
        "Implementation eines RadixTrees."
      ],
      "metadata": {
        "id": "sjY2oRI3_jVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RadixTree:\n",
        "    \"\"\"contains a dict, which links to multiple RadixTree's. The key to another tree is a str and\n",
        "    if a transition ends in a word, the isWord-variable is True\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, isWord=False, transitions=None):\n",
        "        if transitions is None:\n",
        "            transitions = dict()\n",
        "        self.isWord = isWord\n",
        "        self.transitions = transitions\n",
        "\n",
        "    def insertWord(self, word):\n",
        "        \"\"\"inserts a word into the tree\n",
        "\n",
        "        Args:\n",
        "            word (str): is the str, that gets inserted\n",
        "        \"\"\"\n",
        "        for i in range(0, len(word)):\n",
        "            # goes through 'tobi' with 'tobi', 'tob', 'to', 't'\n",
        "            possibleTransition = word[:len(word) - i]\n",
        "            if self.transitions.get(possibleTransition) is not None:\n",
        "                child = self.transitions.get(possibleTransition)\n",
        "                if possibleTransition == word:\n",
        "                    child.isWord = True\n",
        "                else:\n",
        "                    child.insertWord(word[len(possibleTransition):])\n",
        "                return\n",
        "\n",
        "            for key in self.transitions.keys():\n",
        "                if possibleTransition == key[:len(possibleTransition)]:\n",
        "                    child = self.transitions.pop(key)\n",
        "                    newDict = dict()\n",
        "                    newDict[key[len(possibleTransition):]] = child\n",
        "                    self.transitions[possibleTransition] = RadixTree(possibleTransition == word, newDict)\n",
        "                    if possibleTransition != word:\n",
        "                        self.transitions[possibleTransition].insertWord(word[len(possibleTransition):])\n",
        "                    return\n",
        "\n",
        "        self.transitions[word] = RadixTree(True, dict())\n",
        "\n",
        "    def __strRecursive__(self, timesOfIndentation, lengthOfTransitionString):\n",
        "        result = \"\"\n",
        "        if self.isWord:\n",
        "            result += \".\"\n",
        "        keys = list(self.transitions.keys())\n",
        "        keys.sort()\n",
        "        for key in keys:\n",
        "            recursiveResult = self.transitions[key].__strRecursive__(timesOfIndentation + lengthOfTransitionString,\n",
        "                                                                     len(key))\n",
        "            result += \"\\n\" + (timesOfIndentation + lengthOfTransitionString) * \"_\" + key + recursiveResult\n",
        "        return result\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"generates a readable str, containing all class variables (the tree).\n",
        "\n",
        "        Returns:\n",
        "            str: the generated str\n",
        "        \"\"\"\n",
        "        return self.__strRecursive__(0, 0)\n",
        "\n",
        "    def getSimilarWordsOfSameLength(self, maximumDifferentLetters, word):\n",
        "        \"\"\"compares the given word with entries of the same length. Returns all of them with less or equal different letters than with maximumDifferentLetters described\n",
        "\n",
        "        Args:\n",
        "            maximumDifferentLetters (int): limits the amount of accepted different letters when comparing 2 words\n",
        "            word (str): the given word\n",
        "\n",
        "        Returns:\n",
        "            list: returns a list of similar words with the same length. Does contain itself\n",
        "        \"\"\"\n",
        "        if word == \"\":\n",
        "            return [word] if self.isWord else []\n",
        "\n",
        "        resultList = list()\n",
        "        for key in self.transitions.keys():\n",
        "            if len(key) > len(word):\n",
        "                continue\n",
        "            differences = 0\n",
        "            for i in range(0, len(key)):\n",
        "                differences += word[i] != key[i]\n",
        "                if differences > maximumDifferentLetters:\n",
        "                    break\n",
        "\n",
        "            if differences > maximumDifferentLetters:\n",
        "                continue\n",
        "            resultTmp = self.transitions[key].getSimilarWordsOfSameLength(maximumDifferentLetters - differences,\n",
        "                                                                          word[len(key):])\n",
        "            if resultTmp:\n",
        "                resultList.extend([key + tmp for tmp in resultTmp])\n",
        "        return resultList\n"
      ],
      "metadata": {
        "id": "dYT__cinAe6A"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RadixTreesByWordLength\n",
        "Ein Container, der Wörter je nach Länge in unterschiedliche RadixTrees ablegt und ansonsten wie ein Tree agiert."
      ],
      "metadata": {
        "id": "Gs-NXTuf_kfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RadixTreesByWordLength:\n",
        "    \"\"\"contains a dict, which links to multiple RadixTree's, each storing words of the same length\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.radixTrees = dict()\n",
        "\n",
        "    def insertWord(self, word):\n",
        "        \"\"\"inserts a word into the tree\n",
        "\n",
        "        Args:\n",
        "            word (str): is the str, that gets inserted\n",
        "        \"\"\"\n",
        "        length = len(word)\n",
        "        if self.radixTrees.get(length) is None:\n",
        "            self.radixTrees[length] = RadixTree()\n",
        "        self.radixTrees[length].insertWord(word)\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"generates a readable str, containing all class variables (the tree)\n",
        "\n",
        "        Returns:\n",
        "            str: the generated str\n",
        "        \"\"\"\n",
        "        tmp = \"\"\n",
        "        lengthStr = self.radixTrees.keys()\n",
        "        sortedLengths = [int(lengths) for lengths in lengthStr]\n",
        "        sortedLengths.sort()\n",
        "\n",
        "        for length in sortedLengths:\n",
        "            tmp += \"RadixTree with words of length \" + str(length) + \":\"\n",
        "            tmp += self.radixTrees[length].__str__()\n",
        "            tmp += \"\\n\"\n",
        "        return tmp\n",
        "\n",
        "    def getSimilarWordsOfSameLength(self, maximumDifferentLetters, word):\n",
        "        \"\"\"compares the given word with entries of the same length. Returns all of them with less or equal different letters than with maximumDifferentLetters described\n",
        "\n",
        "        Args:\n",
        "            maximumDifferentLetters (int): limits the amount of accepted different letters when comparing 2 words\n",
        "            word (str): the given word\n",
        "\n",
        "        Returns:\n",
        "            list: returns a list of similar words with the same length. Does contain itself\n",
        "        \"\"\"\n",
        "        length = len(word)\n",
        "        if self.radixTrees.get(length) is None:\n",
        "            return []\n",
        "        return self.radixTrees[length].getSimilarWordsOfSameLength(maximumDifferentLetters, word)\n"
      ],
      "metadata": {
        "id": "mIsL8VDqBM5m"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Name Extraction"
      ],
      "metadata": {
        "id": "7cdFeQY3xBge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import re\n",
        "# install and import Entrez and Medline first\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "try:\n",
        "    from Bio import Entrez, Medline\n",
        "except:\n",
        "    # One of these 2 lines should work\n",
        "    # !pip install Bio\n",
        "    install('Bio')\n",
        "from Bio import Entrez, Medline\n",
        "\n",
        "\n",
        "def getPapers(myQuery, maxPapers, myEmail=\"freytag64@gmail.com\"):\n",
        "    \"\"\"retrieves some Papers from Pubmed\n",
        "\n",
        "    Args:\n",
        "        myQuery (str): is the given Query \n",
        "        maxPapers (int): is a limit of the number of papers, which will be retrieved\n",
        "        myEmail (str, optional): an email. Defaults to \"freytag64@gmail.com\".\n",
        "\n",
        "    Returns:\n",
        "        list: papers as list of dictionarys containing abstract, authors, ...\n",
        "    \"\"\"\n",
        "    # Get articles from PubMed\n",
        "    Entrez.email = myEmail\n",
        "    record = Entrez.read(Entrez.esearch(db=\"pubmed\", term=myQuery, retmax=maxPapers))\n",
        "    idlist = record[\"IdList\"]\n",
        "    print(\"\\nThere are %d records for %s.\" % (len(idlist), myQuery.strip()))\n",
        "    records = Medline.parse(Entrez.efetch(db=\"pubmed\", id=idlist, rettype=\"medline\", retmode=\"text\"))\n",
        "    return list(records)\n",
        "\n",
        "\n",
        "def retrieveAllFirstNames(records):\n",
        "    \"\"\"takes list of papers (each is a dict) and extracts the first names as a combined list with a regular expression \n",
        "\n",
        "    Args:\n",
        "        records (list): list of papers\n",
        "\n",
        "    Returns:\n",
        "        list: list of first names as str's\n",
        "    \"\"\"\n",
        "    # retrieves first names from authors with regular expressions\n",
        "    firstNameList = list()\n",
        "    for record in filter(lambda x: 'FAU' in x, records):\n",
        "        for fullName in record['FAU']:\n",
        "            try:\n",
        "                # since names are formatted like 'Lastname, Firstnames', split by ',' to get Firstnames\n",
        "                firstName = fullName.split(',')[1].strip().lower()\n",
        "                names1 = list(filter(lambda x: len(x) > 1, firstName.split()))\n",
        "                firstNameList.extend(names1)\n",
        "                # print(fullName + \" --> \" + str(names1))\n",
        "                \n",
        "                # fixed: does not get name-pairs like \"le Roux, Marlene F\", since the lastname 'Roux' starts with ' ' too\n",
        "                # fixed (see comment): does not really get name-pairs like \"Something, A Mohammed\", since A is just a single letter (it ignores A as a firstname)\n",
        "                # a better one can be generated by using Multiple Sequence Alignment from the lectures. Names like Al-Abehd with '-' are just added as 'Al-Abehd' too.\n",
        "                # sometimes accepts stuff like 'jr'\n",
        "            except:\n",
        "                pass\n",
        "            \n",
        "            \"\"\"\n",
        "            expression = r' ([a-zA-Z_-][a-zA-Z_-]+)'\n",
        "            names2 = re.findall(expression, fullName)\n",
        "            # firstNameList.extend(names2)            \n",
        "            \n",
        "            if names1 != names2:\n",
        "              print(fullName + \" --> \" + str(names1))\n",
        "              print(fullName + \" --> \" + str(names2))\n",
        "            \"\"\"\n",
        "\n",
        "    return firstNameList"
      ],
      "metadata": {
        "id": "mkmbJXjYxHzk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clustering\n",
        "Clustern der Namen mit einer DBSCAN-ähnlichen Methode.\n",
        "\n",
        "Unterschiede:\n",
        "- zu große Cluster werden strenger erneut geclustert (maximale Größe: 1000 Namen)\n",
        "- beim Prüfen, ob ein Knoten ein Kernknoten ist, zählen bereits erkundete Knoten nicht mehr\n",
        "- Namen mit Länge 2 oder kürzer werden ignoriert\n",
        "\n",
        "Ein Kernknoten braucht mindestens 6 unbesuchte Nachbarn um als Kernknoten zu gelten.\n",
        "\n",
        "Eliminiert nicht erreichbare Knoten.\n",
        "\n",
        "Knoten: einzelne Namen\n",
        "\n",
        "Knotenübergänge (ungerichtet) zwischen Namen gleicher Länge mit maximaler Hamming-Distanz 1"
      ],
      "metadata": {
        "id": "mFkZHyruSPEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getNames() -> list:\n",
        "    \"\"\"reads names from external file (removes duplicates)\n",
        "\n",
        "    Returns:\n",
        "        list: list of firstnames\n",
        "    \"\"\"\n",
        "    print(\"reads in names from external list\")\n",
        "    names = list()\n",
        "    with open(\"2022FirstNames\", \"r\") as myfile:\n",
        "        try:\n",
        "            names = list(set(myfile.read().split()))\n",
        "        finally:\n",
        "            myfile.close()\n",
        "\n",
        "    print(\"names in total: \" + str(len(names)))\n",
        "    \n",
        "    return names\n",
        "\n",
        "def getClusters() -> list:\n",
        "    \"\"\"reads in clusters from external file\n",
        "\n",
        "    Returns:\n",
        "        list: is list of clusters (list of names)\n",
        "    \"\"\"\n",
        "    print(\"reads in clusters from external list\")\n",
        "    clusters = list()\n",
        "    with open(\"clusteredNames\", \"r\") as myfile:\n",
        "        try:\n",
        "            clusterAsStrings = myfile.read().split(\"\\n\")\n",
        "            for string in clusterAsStrings:\n",
        "                clusters.append(string.split())\n",
        "        finally:\n",
        "            myfile.close()\n",
        "\n",
        "    print(\"clusters in total: \" + str(len(clusters)))\n",
        "    \n",
        "    return clusters\n",
        "    \n",
        "\n",
        "def Dbscan(names : list, min_samples : int, min_word_length : int, max_cluster_length : int) -> list:\n",
        "    \"\"\"clusters list of names with DBSCAN\n",
        "\n",
        "    Args:\n",
        "        names (list): list of names\n",
        "        min_samples (int): the number of samples in a neighborhood for a point to be considered a core point\n",
        "        min_word_length (int): only words with this length or longer are clustered\n",
        "        max_cluster_length (int): maximum size of cluster. If found cluster are bigger, they will devided\n",
        "    Returns:\n",
        "        list: list of clusters (each cluster is a list of names)\n",
        "    \"\"\"\n",
        "    \n",
        "    tree = RadixTreesByWordLength()\n",
        "    clusters = list()\n",
        "    names = list(filter(lambda x : len(x) >= min_word_length, names))\n",
        "    names.sort(reverse=True)\n",
        "    \n",
        "    tmp = list()\n",
        "    for n in names:\n",
        "        tmp.append(n.lower())\n",
        "    names = tmp\n",
        "    \n",
        "    #construct the RadixTree\n",
        "    for n in names:\n",
        "        tree.insertWord(n)\n",
        "    \n",
        "    #clustering\n",
        "    while len(names) > 0:\n",
        "        name = names.pop()\n",
        "        cluster = set()\n",
        "        stack = [name]\n",
        "        \n",
        "        #fill cluster\n",
        "        while len(stack) > 0:\n",
        "            node = stack.pop()\n",
        "            \n",
        "            #check if name is a core-sample\n",
        "            neighbors = tree.getSimilarWordsOfSameLength(1, node)\n",
        "            #already found nodes are not considered as neighbors\n",
        "            toBeRemoved = list()\n",
        "            for n in neighbors:\n",
        "                if n in cluster:\n",
        "                    toBeRemoved.append(n)\n",
        "                    continue\n",
        "                for c in clusters:\n",
        "                    if n in c:\n",
        "                        toBeRemoved.append(n)\n",
        "            for n in toBeRemoved:\n",
        "                neighbors.remove(n) \n",
        "                \n",
        "            #add new names to cluster\n",
        "            if len(neighbors) >= min_samples:\n",
        "                for n in filter(lambda x : x in names, neighbors):\n",
        "                    names.remove(n)\n",
        "                stack.extend(neighbors)\n",
        "                cluster.update(set(neighbors))\n",
        "        \n",
        "        cluster = list(cluster)\n",
        "        #add filled cluster\n",
        "        if len(cluster) > 1 and len(cluster) <= max_cluster_length:\n",
        "            clusters.append(cluster)\n",
        "        #if a cluster is too big, cluster it again\n",
        "        elif len(cluster) > max_cluster_length:\n",
        "            smallerClusters = Dbscan(cluster, min_samples + 5, min_word_length, max_cluster_length)\n",
        "            clusters.extend(smallerClusters)    \n",
        "\n",
        "    return clusters\n",
        "            "
      ],
      "metadata": {
        "id": "_mjXEEIbUC_L"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names = getNames()\n",
        "\n",
        "print(\"clustering (takes a while):\")\n",
        "clusters = Dbscan(names, 6, 3, 1000)\n",
        "\n",
        "print(str(len(clusters)) + \" different clusters\")\n",
        "i = 0\n",
        "for c in clusters:\n",
        "    i += len(c)\n",
        "print(str(i) + \" names clustered\")\n",
        "\n",
        "#save in file\n",
        "with open(\"clusteredNames\", \"w+\") as myfile:\n",
        "    try:\n",
        "        tmp = \"\"\n",
        "        for cluster in clusters:\n",
        "            for name in cluster:\n",
        "                tmp += name + \" \"\n",
        "            tmp += \"\\n\"\n",
        "        myfile.write(tmp)\n",
        "    finally:\n",
        "        myfile.close()"
      ],
      "metadata": {
        "id": "VOBIPmEGVDUA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "cf0c25ab-1058-4733-a83e-7285bd4db081"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reads in names from external list\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2ee2e6572288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"clustering (takes a while):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDbscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-03ef9e6d4328>\u001b[0m in \u001b[0;36mgetNames\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reads in names from external list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2022FirstNames\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmyfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2022FirstNames'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SubstitutionMatrix\n",
        "Implementation einer Substitutionsmatrix, ähnlich BLOSUM. Ignoriert aktuell alle Buchstaben, die nicht im ASCII kodiert sind.\n",
        "\n",
        "Matrixeinträge werden nach folgender Formel berechnet: \n",
        "$$ S_{i,j} = \\frac{1}{\\lambda} \\cdot \\log{\\frac{p_{ij}}{q_i \\cdot q_j}} $$\n",
        "$ \\lambda $ ... (frei wählbarer) Skalierungsfaktor\n",
        "\n",
        "$ p_{ij} $ ... Wahrscheinlichkeit, dass (innerhalb eines Clusters) i durch j ersetzt wird\n",
        "\n",
        "$ q_i, q_j $ ... Wahrscheinlichkeiten, dass i bzw. j in einem Wort auftritt"
      ],
      "metadata": {
        "id": "SxfUiN4P_k7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "class SubstitutionMatrix:\n",
        "\n",
        "    def __init__(self, names: list, clusters: list, scaling: float = 1):\n",
        "        \"\"\"\n",
        "        Initializes and calculates a Substitution-Matrix out of the given names, clustering and scaling\n",
        "\n",
        "        :param names: list of all names used to calculate matrix\n",
        "        :param clusters: list of clusters which are lists of similar names\n",
        "        :param scaling: optional scaling factor\n",
        "        \"\"\"\n",
        "        self.letters = [\n",
        "            'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u',\n",
        "            'v', 'w', 'x', 'y', 'z']\n",
        "\n",
        "        self.name_occurrences = self.calc_name_occurrences(names)\n",
        "\n",
        "        self.letter_prob = self.calc_letter_prob()\n",
        "\n",
        "        self.clusters = clusters\n",
        "\n",
        "        self.scaling = scaling\n",
        "\n",
        "        self.sub_probs = self.calc_sub_probs()\n",
        "\n",
        "        self.substitution_matrix = self.calc_substitution_matrix()\n",
        "\n",
        "    def calc_name_occurrences(self, all_names: list) -> dict:\n",
        "        \"\"\"\n",
        "        Calculates the number of duplicates for each name in all_names\n",
        "\n",
        "        :param all_names: list of all names used to calculate the matrix\n",
        "        :return: a dictionary mapping every name to its number of occurrences\n",
        "        \"\"\"\n",
        "        print(\"Calculating name occurrences...\")\n",
        "\n",
        "        result = dict()\n",
        "        names, count = np.unique(all_names, return_counts=True)\n",
        "        for i in range(len(names)):\n",
        "            result[names[i]] = count[i]\n",
        "\n",
        "        print(\"done\")\n",
        "        return result\n",
        "\n",
        "    def calc_letter_prob(self) -> dict:\n",
        "        \"\"\"\n",
        "        Calculates the probability of every letter to be in a name\n",
        "\n",
        "        :return: a dictionary mapping every letter to its probability of being in a name\n",
        "        \"\"\"\n",
        "        print(\"Calculating probability of letters...\")\n",
        "\n",
        "        letter_counts = defaultdict(int)\n",
        "\n",
        "        n = 0\n",
        "        for (name, count) in self.name_occurrences.items():\n",
        "            for x in {c for c in name}:\n",
        "                if x in self.letters:\n",
        "                    letter_counts[x] += count\n",
        "            n += count\n",
        "\n",
        "        letter_prob = defaultdict(int)\n",
        "        for (x, occurrences) in letter_counts.items():\n",
        "            letter_prob[x] = occurrences / n\n",
        "\n",
        "        print(\"done\")\n",
        "        return letter_prob\n",
        "\n",
        "    def calc_sub_probs(self) -> dict:\n",
        "        \"\"\"\n",
        "        Calculates the probability of one letter to be substituted by another letter\n",
        "\n",
        "        :return: a matrix with substitution probabilities for each letter\n",
        "        \"\"\"\n",
        "        print(\"Calculating probability of substitutions...\")\n",
        "\n",
        "        sub_probs = dict()\n",
        "        for x in self.letters:\n",
        "            sub_probs[x] = dict()\n",
        "            for y in self.letters:\n",
        "                sub_probs[x][y] = (0, 0)  # (prob, #examples)\n",
        "\n",
        "        for cluster in self.clusters:\n",
        "            for i in range(len(cluster[0])):\n",
        "                occurrences = defaultdict(int)\n",
        "                sum_occurrences = 0\n",
        "                for name in cluster:\n",
        "                    n = self.name_occurrences[name]\n",
        "                    letter = name[i]\n",
        "                    if letter in self.letters:\n",
        "                        occurrences[name[i]] += n\n",
        "                        sum_occurrences += n\n",
        "\n",
        "                for a in occurrences.keys():\n",
        "                    for b in occurrences.keys():\n",
        "                        (p_old, n_old) = sub_probs[a][b]\n",
        "                        n_new = sum(occurrences.values())\n",
        "                        p_new = occurrences[a] * occurrences[b] / n_new\n",
        "                        if a != b:\n",
        "                            p_new *= 2\n",
        "                        sub_probs[a][b] = ((p_new + p_old) / (n_old + n_new), n_old + n_new)\n",
        "\n",
        "        for a in self.letters:\n",
        "            for b in self.letters:\n",
        "                sub_probs[a][b] = sub_probs[a][b][0]\n",
        "        print(\"done\")\n",
        "        return sub_probs\n",
        "\n",
        "    def calc_substitution_matrix(self) -> dict:\n",
        "        \"\"\"\n",
        "        Calculates the Substitution-Matrix\n",
        "\n",
        "        :return: a matrix with substitution values for each letter\n",
        "        \"\"\"\n",
        "        print(\"Calculating substitution matrix...\")\n",
        "\n",
        "        matrix = defaultdict(dict)\n",
        "        min = float(\"inf\")\n",
        "        for a in self.letters:\n",
        "            for b in self.letters:\n",
        "                try:\n",
        "                    if self.sub_probs[a][b] == 0:\n",
        "                        matrix[a][b] = \"min\"\n",
        "                    else:\n",
        "                        matrix[a][b] = (self.scaling ** (-1)) * np.log2(10 *\n",
        "                            self.sub_probs[a][b] / (self.letter_prob[a] * self.letter_prob[b]))\n",
        "                        if matrix[a][b] < min:\n",
        "                            min = matrix[a][b]\n",
        "                except ZeroDivisionError:\n",
        "                    matrix[a][b] = \"min\"\n",
        "\n",
        "        for a in matrix.keys():\n",
        "            for b in matrix[a].keys():\n",
        "                if matrix[a][b] == \"min\":\n",
        "                    matrix[a][b] = min\n",
        "\n",
        "        print(\"done\")\n",
        "        return matrix\n",
        "\n",
        "    def set_names(self, names: list, clusters: list = None):\n",
        "        \"\"\"\n",
        "        Sets a new list of names (and a new clustering) as basis and calculates the new Substitution-Matrix\n",
        "\n",
        "        :param names: list(str)\n",
        "        :param clusters: list(list(str))\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.__init__(names, clusters if clusters else self.clusters, self.scaling)\n",
        "\n",
        "    def set_clusters(self, clusters: list):\n",
        "        \"\"\"\n",
        "        Sets a new clustering and calculates the new Substitution-Matrix\n",
        "\n",
        "        :param clusters: list(list(str))\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.clusters = clusters\n",
        "        self.sub_probs = self.calc_sub_probs()\n",
        "        self.substitution_matrix = self.calc_substitution_matrix()\n",
        "\n",
        "    def set_scaling(self, scaling: float):\n",
        "        \"\"\"\n",
        "        Set a new scaling and calculate the new Substitution-Matrix\n",
        "        :param scaling:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if self.scaling != scaling:\n",
        "            self.scaling = scaling\n",
        "            self.substitution_matrix = self.calc_substitution_matrix()\n",
        "\n",
        "    def __str__(self):\n",
        "        tmp = \"Substitutionsmatrix:\\n  \"\n",
        "        for to in self.letters:\n",
        "            tmp += \"\\t\" + to\n",
        "        tmp += \"\\n\"\n",
        "\n",
        "        for fr in self.letters:\n",
        "            tmp += fr\n",
        "            for to in self.letters:\n",
        "                strEntry = str(self.substitution_matrix[fr][to])\n",
        "                if len(strEntry) < 4:\n",
        "                    strEntry = (4 - len(strEntry)) * \"0\" + strEntry\n",
        "                tmp += \"\\t\" + strEntry[:4]\n",
        "            tmp += \"\\n\"\n",
        "        return tmp\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "[(Klaus, 10), (Claus, 5), (Klaas, 15)]\n",
        "P(K - C) = 2 * (5/6 * 1/6) = 10/36\n",
        "P(K - K) = 5/6 * 5/6 = 25/36\n",
        "P(C - C) = 1/6 * 1/6 = 1/36\n",
        "\n",
        "[(Klara, 2), (Clara, 4), (Clars, 4)]\n",
        "P(K - C) = 2 * (1/5 * 4/5) = 8/25\n",
        "P(K - K) = 1/5 * 1/5 = 1/25\n",
        "P(C - C) = 4/5 * 4/5 = 16/25\n",
        "\n",
        "names = [(\"klara\", 2), (\"clara\", 4), (\"clars\", 4), (\"klaus\", 10), (\"claus\", 5), (\"klaas\", 15)]\n",
        "all_names = []\n",
        "for (name, count) in names:\n",
        "    for i in range(count):\n",
        "        all_names.append(name)\n",
        "\n",
        "clusters = [[\"klaus\", \"claus\", \"klaas\"], [\"klara\", \"clara\", \"clars\"]]\n",
        "\n",
        "matrix = SubstitutionMatrix(all_names, clusters)\n",
        "print(matrix)\n",
        "#\"\"\"\n"
      ],
      "metadata": {
        "id": "bWIfBEgBB9Rh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "2b3a1fcb-1c64-4f3b-e233-1fe9264278ff"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n[(Klaus, 10), (Claus, 5), (Klaas, 15)]\\nP(K - C) = 2 * (5/6 * 1/6) = 10/36\\nP(K - K) = 5/6 * 5/6 = 25/36\\nP(C - C) = 1/6 * 1/6 = 1/36\\n\\n[(Klara, 2), (Clara, 4), (Clars, 4)]\\nP(K - C) = 2 * (1/5 * 4/5) = 8/25\\nP(K - K) = 1/5 * 1/5 = 1/25\\nP(C - C) = 4/5 * 4/5 = 16/25\\n\\nnames = [(\"klara\", 2), (\"clara\", 4), (\"clars\", 4), (\"klaus\", 10), (\"claus\", 5), (\"klaas\", 15)]\\nall_names = []\\nfor (name, count) in names:\\n    for i in range(count):\\n        all_names.append(name)\\n\\nclusters = [[\"klaus\", \"claus\", \"klaas\"], [\"klara\", \"clara\", \"clars\"]]\\n\\nmatrix = SubstitutionMatrix(all_names, clusters)\\nprint(matrix)\\n#'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo"
      ],
      "metadata": {
        "id": "ynv0JA_3zcvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxPapers = 10000  # limit the number of papers retrieved\n",
        "myQuery = \"(\\\"2021/01/20\\\"[Date - Publication] : \\\"2021/01/20\\\"[Date - Publication])\"\n",
        "records = getPapers(myQuery, maxPapers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmHo3fvYwT0q",
        "outputId": "2e1a380d-4887-49f0-adb7-1a5c22bad68a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "There are 4926 records for (\"2021/01/20\"[Date - Publication] : \"2021/01/20\"[Date - Publication]).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names = retrieveAllFirstNames(records)"
      ],
      "metadata": {
        "id": "dtGThfuN3L9r"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clusters = Dbscan(names, 6, 3, 100)"
      ],
      "metadata": {
        "id": "zWbVpj7C3PNt"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: autoscale\n",
        "matrix = SubstitutionMatrix(names, clusters)\n",
        "print(matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T35EwPkd3Rda",
        "outputId": "a917471d-c003-4969-c24d-337982c9ef68"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating name occurrences...\n",
            "done\n",
            "Calculating probability of letters...\n",
            "done\n",
            "Calculating probability of substitutions...\n",
            "done\n",
            "Calculating substitution matrix...\n",
            "done\n",
            "Substitutionsmatrix:\n",
            "  \ta\tb\tc\td\te\tf\tg\th\ti\tj\tk\tl\tm\tn\to\tp\tq\tr\ts\tt\tu\tv\tw\tx\ty\tz\n",
            "a\t-11.\t-4.5\t0.63\t-4.4\t-4.5\t0.74\t-6.0\t-4.6\t-6.9\t-1.5\t-5.7\t-5.0\t-5.0\t-5.9\t-5.1\t-5.4\t-3.0\t-5.2\t-5.0\t-1.3\t-6.5\t1.49\t-3.4\t-1.9\t-3.6\t-3.7\n",
            "b\t-4.5\t-4.0\t-2.9\t-3.0\t1.54\t-0.9\t-3.1\t-1.1\t-9.2\t-1.4\t0.02\t-3.8\t-3.1\t-5.1\t0.58\t-2.2\t3.01\t-2.4\t0.38\t-4.3\t6.64\t1.97\t1.13\t1.12\t-2.2\t0.73\n",
            "c\t0.63\t-2.9\t-6.3\t-2.2\t-2.2\t-7.0\t-1.5\t-3.7\t-2.7\t-1.0\t-1.4\t-3.9\t-0.6\t-5.9\t-8.1\t-1.7\t-0.2\t-3.0\t-5.3\t-3.8\t-1.1\t2.98\t-6.9\t2.84\t-3.3\t0.61\n",
            "d\t-4.4\t-3.0\t-2.2\t-7.6\t-9.3\t-2.5\t-3.3\t-5.1\t-4.6\t-2.0\t-1.6\t-4.7\t-2.7\t-7.0\t-7.5\t-3.4\t-2.6\t-6.0\t-6.7\t-5.8\t-0.6\t0.76\t1.90\t-1.6\t-2.9\t-1.0\n",
            "e\t-4.5\t1.54\t-2.2\t-9.3\t-4.7\t-2.4\t0.15\t-5.6\t-4.4\t-4.5\t-0.9\t-0.6\t-1.2\t-4.7\t-4.9\t-1.1\t0.49\t-3.3\t-8.7\t-4.4\t-4.4\t-3.5\t-1.6\t0.23\t-3.8\t3.52\n",
            "f\t0.74\t-0.9\t-7.0\t-2.5\t-2.4\t-1.1\t-1.4\t-1.8\t0.79\t0.75\t-4.1\t-1.2\t-0.7\t-3.2\t-4.3\t2.39\t4.22\t1.00\t-5.1\t-4.6\t-11.\t1.52\t2.15\t2.63\t0.73\t2.43\n",
            "g\t-6.0\t-3.1\t-1.5\t-3.3\t0.15\t-1.4\t-0.1\t-2.5\t-7.3\t-4.4\t-0.4\t-6.0\t-2.5\t-3.6\t-7.8\t-2.9\t-0.1\t-4.8\t-7.6\t-4.7\t-11.\t-0.4\t0.15\t-2.0\t-3.5\t0.04\n",
            "h\t-4.6\t-1.1\t-3.7\t-5.1\t-5.6\t-1.8\t-2.5\t-4.0\t-6.3\t-1.5\t-2.6\t-6.3\t-1.3\t-3.1\t-7.5\t-0.8\t-2.0\t-5.2\t-5.8\t-4.9\t-1.9\t-3.6\t-1.7\t-0.5\t-2.1\t-2.5\n",
            "i\t-6.9\t-9.2\t-2.7\t-4.6\t-4.4\t0.79\t-7.3\t-6.3\t-6.1\t0.62\t-2.4\t-4.4\t-3.5\t-5.6\t-5.4\t-2.3\t-2.6\t-8.0\t-4.2\t-3.9\t-4.5\t-4.6\t-0.0\t-8.7\t-1.4\t-3.6\n",
            "j\t-1.5\t-1.4\t-1.0\t-2.0\t-4.5\t0.75\t-4.4\t-1.5\t0.62\t-5.4\t-3.6\t-4.9\t-2.0\t-4.3\t-3.9\t-1.2\t0.73\t-5.4\t-5.9\t-5.4\t4.77\t-1.7\t-0.3\t1.43\t-2.5\t0.16\n",
            "k\t-5.7\t0.02\t-1.4\t-1.6\t-0.9\t-4.1\t-0.4\t-2.6\t-2.4\t-3.6\t-5.2\t-4.6\t-3.5\t-2.0\t-0.7\t-5.6\t2.98\t-1.5\t-4.8\t-1.6\t2.84\t0.21\t-0.9\t0.76\t-0.5\t0.86\n",
            "l\t-5.0\t-3.8\t-3.9\t-4.7\t-0.6\t-1.2\t-6.0\t-6.3\t-4.4\t-4.9\t-4.6\t-8.0\t-3.8\t-4.7\t-7.3\t-3.2\t0.01\t-6.0\t-7.3\t-6.9\t2.59\t1.02\t-2.8\t-0.2\t-2.7\t-1.5\n",
            "m\t-5.0\t-3.1\t-0.6\t-2.7\t-1.2\t-0.7\t-2.5\t-1.3\t-3.5\t-2.0\t-3.5\t-3.8\t-5.5\t-6.3\t-3.0\t-2.8\t-2.2\t-3.6\t-1.9\t-5.2\t-2.2\t3.74\t-3.5\t-2.6\t-2.3\t-4.4\n",
            "n\t-5.9\t-5.1\t-5.9\t-7.0\t-4.7\t-3.2\t-3.6\t-3.1\t-5.6\t-4.3\t-2.0\t-4.7\t-6.3\t-5.2\t-3.9\t-5.0\t-1.2\t-5.5\t-4.8\t-8.1\t-3.1\t0.86\t-2.0\t-4.2\t-4.1\t-2.8\n",
            "o\t-5.1\t0.58\t-8.1\t-7.5\t-4.9\t-4.3\t-7.8\t-7.5\t-5.4\t-3.9\t-0.7\t-7.3\t-3.0\t-3.9\t-7.4\t-1.2\t-3.9\t-4.4\t-5.9\t-3.1\t-1.5\t-0.9\t-3.5\t-5.5\t-5.7\t-8.7\n",
            "p\t-5.4\t-2.2\t-1.7\t-3.4\t-1.1\t2.39\t-2.9\t-0.8\t-2.3\t-1.2\t-5.6\t-3.2\t-2.8\t-5.0\t-1.2\t1.85\t1.86\t-2.5\t-3.0\t-2.3\t-11.\t1.08\t-0.8\t1.91\t-1.5\t-1.2\n",
            "q\t-3.0\t3.01\t-0.2\t-2.6\t0.49\t4.22\t-0.1\t-2.0\t-2.6\t0.73\t2.98\t0.01\t-2.2\t-1.2\t-3.9\t1.86\t0.39\t-2.1\t-1.2\t-1.0\t-11.\t6.96\t-0.7\t0.76\t0.94\t0.98\n",
            "r\t-5.2\t-2.4\t-3.0\t-6.0\t-3.3\t1.00\t-4.8\t-5.2\t-8.0\t-5.4\t-1.5\t-6.0\t-3.6\t-5.5\t-4.4\t-2.5\t-2.1\t-7.9\t-6.3\t-6.2\t-1.5\t-1.9\t-0.7\t-3.4\t-3.0\t-4.1\n",
            "s\t-5.0\t0.38\t-5.3\t-6.7\t-8.7\t-5.1\t-7.6\t-5.8\t-4.2\t-5.9\t-4.8\t-7.3\t-1.9\t-4.8\t-5.9\t-3.0\t-1.2\t-6.3\t-8.8\t-6.6\t-1.4\t-0.2\t-3.7\t-3.2\t-3.9\t-0.7\n",
            "t\t-1.3\t-4.3\t-3.8\t-5.8\t-4.4\t-4.6\t-4.7\t-4.9\t-3.9\t-5.4\t-1.6\t-6.9\t-5.2\t-8.1\t-3.1\t-2.3\t-1.0\t-6.2\t-6.6\t-8.1\t-0.5\t-1.6\t-3.8\t-3.8\t-3.3\t-0.8\n",
            "u\t-6.5\t6.64\t-1.1\t-0.6\t-4.4\t-11.\t-11.\t-1.9\t-4.5\t4.77\t2.84\t2.59\t-2.2\t-3.1\t-1.5\t-11.\t-11.\t-1.5\t-1.4\t-0.5\t-1.0\t0.48\t0.33\t-11.\t-6.9\t2.66\n",
            "v\t1.49\t1.97\t2.98\t0.76\t-3.5\t1.52\t-0.4\t-3.6\t-4.6\t-1.7\t0.21\t1.02\t3.74\t0.86\t-0.9\t1.08\t6.96\t-1.9\t-0.2\t-1.6\t0.48\t-2.3\t5.77\t4.86\t-1.7\t1.82\n",
            "w\t-3.4\t1.13\t-6.9\t1.90\t-1.6\t2.15\t0.15\t-1.7\t-0.0\t-0.3\t-0.9\t-2.8\t-3.5\t-2.0\t-3.5\t-0.8\t-0.7\t-0.7\t-3.7\t-3.8\t0.33\t5.77\t-3.0\t0.43\t-1.6\t-2.6\n",
            "x\t-1.9\t1.12\t2.84\t-1.6\t0.23\t2.63\t-2.0\t-0.5\t-8.7\t1.43\t0.76\t-0.2\t-2.6\t-4.2\t-5.5\t1.91\t0.76\t-3.4\t-3.2\t-3.8\t-11.\t4.86\t0.43\t-1.7\t0.12\t-1.4\n",
            "y\t-3.6\t-2.2\t-3.3\t-2.9\t-3.8\t0.73\t-3.5\t-2.1\t-1.4\t-2.5\t-0.5\t-2.7\t-2.3\t-4.1\t-5.7\t-1.5\t0.94\t-3.0\t-3.9\t-3.3\t-6.9\t-1.7\t-1.6\t0.12\t-2.3\t-0.4\n",
            "z\t-3.7\t0.73\t0.61\t-1.0\t3.52\t2.43\t0.04\t-2.5\t-3.6\t0.16\t0.86\t-1.5\t-4.4\t-2.8\t-8.7\t-1.2\t0.98\t-4.1\t-0.7\t-0.8\t2.66\t1.82\t-2.6\t-1.4\t-0.4\t1.63\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max = float(\"-inf\")\n",
        "min = float(\"inf\")\n",
        "for a in matrix.substitution_matrix.keys():\n",
        "  for b in matrix.substitution_matrix[a].keys():\n",
        "    val = matrix.substitution_matrix[a][b]\n",
        "    if val < min:\n",
        "      min = val\n",
        "    if val > max:\n",
        "      max = val\n",
        "print(min)\n",
        "print(max)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxxdDSyA4dTo",
        "outputId": "07e63029-12d8-48bd-d50f-8fdaf7a197db"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-11.561721174147754\n",
            "6.968179480386764\n"
          ]
        }
      ]
    }
  ]
}