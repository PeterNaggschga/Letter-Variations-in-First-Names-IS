{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMmB8YkASNj5VMD/wuZcx9G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterNaggschga/Letter-Variations-in-First-Names-IS/blob/main/LetterVariationsFirstNames.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RadixTree\n",
        "Implementation eines RadixTrees."
      ],
      "metadata": {
        "id": "sjY2oRI3_jVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RadixTree:\n",
        "    \"\"\"contains a dict, which links to multiple RadixTree's. The key to another tree is a str and\n",
        "    if a transition ends in a word, the isWord-variable is True\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, isWord=False, transitions=None):\n",
        "        if transitions is None:\n",
        "            transitions = dict()\n",
        "        self.isWord = isWord\n",
        "        self.transitions = transitions\n",
        "\n",
        "    def insertWord(self, word):\n",
        "        \"\"\"inserts a word into the tree\n",
        "\n",
        "        Args:\n",
        "            word (str): is the str, that gets inserted\n",
        "        \"\"\"\n",
        "        for i in range(0, len(word)):\n",
        "            # goes through 'tobi' with 'tobi', 'tob', 'to', 't'\n",
        "            possibleTransition = word[:len(word) - i]\n",
        "            if self.transitions.get(possibleTransition) is not None:\n",
        "                child = self.transitions.get(possibleTransition)\n",
        "                if possibleTransition == word:\n",
        "                    child.isWord = True\n",
        "                else:\n",
        "                    child.insertWord(word[len(possibleTransition):])\n",
        "\n",
        "            for key in self.transitions.keys():\n",
        "                if possibleTransition == key[:len(possibleTransition)]:\n",
        "                    child = self.transitions.pop(key)\n",
        "                    newDict = dict()\n",
        "                    newDict[key[len(possibleTransition):]] = child\n",
        "                    self.transitions[possibleTransition] = RadixTree(possibleTransition == word, newDict)\n",
        "                    if possibleTransition != word:\n",
        "                        self.transitions[possibleTransition].insertWord(word[len(possibleTransition):])\n",
        "                    return\n",
        "\n",
        "        self.transitions[word] = RadixTree(True, dict())\n",
        "\n",
        "    def __strRecursive__(self, timesOfIndentation, lengthOfTransitionString):\n",
        "        result = \"\"\n",
        "        if self.isWord:\n",
        "            result += \".\"\n",
        "        keys = list(self.transitions.keys())\n",
        "        keys.sort()\n",
        "        for key in keys:\n",
        "            recursiveResult = self.transitions[key].__strRecursive__(timesOfIndentation + lengthOfTransitionString,\n",
        "                                                                     len(key))\n",
        "            result += \"\\n\" + (timesOfIndentation + lengthOfTransitionString) * \"_\" + key + recursiveResult\n",
        "        return result\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"generates a readable str, containing all class variables (the tree).\n",
        "\n",
        "        Returns:\n",
        "            str: the generated str\n",
        "        \"\"\"\n",
        "        return self.__strRecursive__(0, 0)\n",
        "\n",
        "    def getSimilarWordsOfSameLength(self, maximumDifferentLetters, word):\n",
        "        \"\"\"compares the given word with entries of the same length. Returns all of them with less or equal different letters than with maximumDifferentLetters described\n",
        "\n",
        "        Args:\n",
        "            maximumDifferentLetters (int): limits the amount of accepted different letters when comparing 2 words\n",
        "            word (str): the given word\n",
        "\n",
        "        Returns:\n",
        "            list: returns a list of similar words with the same length. Does contain itself\n",
        "        \"\"\"\n",
        "        if word == \"\":\n",
        "            return [word] if self.isWord else []\n",
        "\n",
        "        resultList = list()\n",
        "        for key in self.transitions.keys():\n",
        "            if len(key) > len(word):\n",
        "                continue\n",
        "            differences = 0\n",
        "            for i in range(0, len(key)):\n",
        "                differences += word[i] != key[i]\n",
        "                if differences > maximumDifferentLetters:\n",
        "                    break\n",
        "\n",
        "            if differences > maximumDifferentLetters:\n",
        "                continue\n",
        "            resultTmp = self.transitions[key].getSimilarWordsOfSameLength(maximumDifferentLetters - differences,\n",
        "                                                                          word[len(key):])\n",
        "            if resultTmp:\n",
        "                resultList.extend([key + tmp for tmp in resultTmp])\n",
        "        return resultList\n"
      ],
      "metadata": {
        "id": "dYT__cinAe6A"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RadixTreesByWordLength\n",
        "Ein Container, der Wörter je nach Länge in unterschiedliche RadixTrees ablegt und ansonsten wie ein Tree agiert."
      ],
      "metadata": {
        "id": "Gs-NXTuf_kfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RadixTreesByWordLength:\n",
        "    \"\"\"contains a dict, which links to multiple RadixTree's, each storing words of the same length\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.radixTrees = dict()\n",
        "\n",
        "    def insertWord(self, word):\n",
        "        \"\"\"inserts a word into the tree\n",
        "\n",
        "        Args:\n",
        "            word (str): is the str, that gets inserted\n",
        "        \"\"\"\n",
        "        length = len(word)\n",
        "        if self.radixTrees.get(length) is None:\n",
        "            self.radixTrees[length] = RadixTree()\n",
        "        self.radixTrees[length].insertWord(word)\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"generates a readable str, containing all class variables (the tree)\n",
        "\n",
        "        Returns:\n",
        "            str: the generated str\n",
        "        \"\"\"\n",
        "        tmp = \"\"\n",
        "        lengthStr = self.radixTrees.keys()\n",
        "        sortedLengths = [int(lengths) for lengths in lengthStr]\n",
        "        sortedLengths.sort()\n",
        "\n",
        "        for length in sortedLengths:\n",
        "            tmp += \"RadixTree with words of length \" + str(length) + \":\"\n",
        "            tmp += self.radixTrees[length].__str__()\n",
        "            tmp += \"\\n\"\n",
        "        return tmp\n",
        "\n",
        "    def getSimilarWordsOfSameLength(self, maximumDifferentLetters, word):\n",
        "        \"\"\"compares the given word with entries of the same length. Returns all of them with less or equal different letters than with maximumDifferentLetters described\n",
        "\n",
        "        Args:\n",
        "            maximumDifferentLetters (int): limits the amount of accepted different letters when comparing 2 words\n",
        "            word (str): the given word\n",
        "\n",
        "        Returns:\n",
        "            list: returns a list of similar words with the same length. Does contain itself\n",
        "        \"\"\"\n",
        "        length = len(word)\n",
        "        if self.radixTrees.get(length) is None:\n",
        "            return []\n",
        "        return self.radixTrees[length].getSimilarWordsOfSameLength(maximumDifferentLetters, word)\n"
      ],
      "metadata": {
        "id": "mIsL8VDqBM5m"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SubstituitionMatrix\n",
        "Implementation einer Substitutionsmatrix."
      ],
      "metadata": {
        "id": "SxfUiN4P_k7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SubstitutionMatrix:\n",
        "    \"\"\"Stores letter-variations as a matrix. The matrix is a dict linking the first letter to a second dict, linking the second letter to its occurrence (int)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.letters = [\n",
        "            'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u',\n",
        "            'v', 'w', 'x', 'y', 'z']\n",
        "        self.matrix = dict()\n",
        "        matrixTmp = dict()\n",
        "        for letter in self.letters:\n",
        "            self.matrix[letter] = dict()\n",
        "            matrixTmp[letter] = 0\n",
        "        for letter in self.letters:\n",
        "            self.matrix[letter] = matrixTmp.copy()\n",
        "        self.totalLetterTransitions = 0\n",
        "\n",
        "    def addLetterTransition(self, fr, to):\n",
        "        \"\"\"adds the transistion from one letter to another in the matrix\n",
        "\n",
        "        Args:\n",
        "            fr (str): a single lower character of the alphabet\n",
        "            to (str): a second single lower character of the alphabet\n",
        "\n",
        "        Returns:\n",
        "            bool: is False if one of the characters was not accepted, True if both were accepted\n",
        "        \"\"\"\n",
        "        if fr not in self.letters or to not in self.letters:\n",
        "            return False\n",
        "\n",
        "        self.matrix[fr][to] += 1\n",
        "        self.totalLetterTransitions += 1\n",
        "        return True\n",
        "\n",
        "    def getMatrixEntryInPercent(self, fr, to):\n",
        "        \"\"\"returns a specific matrix-entry in %\n",
        "\n",
        "        Args:\n",
        "            fr (str): a single lower character of the alphabet\n",
        "            to (str): a second single lower character of the alphabet\n",
        "\n",
        "        Returns:\n",
        "            float: returns -1.0 if one of the given str's was not accepted, the matrix-entry in percent otherwise\n",
        "        \"\"\"\n",
        "        if fr not in self.letters or to not in self.letters:\n",
        "            return -1.0\n",
        "\n",
        "        if self.totalLetterTransitions == 0:\n",
        "            return 0.0\n",
        "        return (self.matrix[fr][to] / self.totalLetterTransitions) * 100\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"generates a readable str for the matrix\n",
        "\n",
        "        Returns:\n",
        "            str: the generated str\n",
        "        \"\"\"\n",
        "\n",
        "        tmp = \"Substitutionmatrix in %:\\n\"\n",
        "        for to in self.matrix.keys():\n",
        "            tmp += \"\\t\" + to\n",
        "        tmp += \"\\n\"\n",
        "        \n",
        "        for fr in self.letters:\n",
        "            tmp += fr\n",
        "            for to in self.letters:\n",
        "                strEntry = str(self.getMatrixEntryInPercent(fr, to))\n",
        "                if len(strEntry) < 4:\n",
        "                    strEntry = (4 - len(strEntry)) * \"0\" + strEntry\n",
        "                tmp += \"\\t\" + strEntry[:4]\n",
        "            tmp += \"\\n\"\n",
        "        return tmp\n",
        "\n",
        "    def addLetterVariationsToMatrix(self, name, similarNames):\n",
        "        \"\"\"retrieves differences of names with the original and inserts these letter-variations into the substitution-matrix\n",
        "\n",
        "        Args:\n",
        "            name (str): is the original name\n",
        "            similarNames (list): list of similar names as str's\n",
        "        \"\"\"\n",
        "        for similarName in similarNames:\n",
        "            for i in range(len(name)):\n",
        "                if name[i] != similarName[i]:\n",
        "                    self.addLetterTransition(name[i], similarName[i])\n",
        "\n",
        "    # here is a simple way of storing and retrieveing the matrix in an external file\n",
        "    \"\"\"\n",
        "    def save(self):\n",
        "        f = open(\"backupFiles/SubstitutionMatrix.txt\", \"w\")\n",
        "        tmp = str(self.totalLetterTransitions) + \";\"\n",
        "        for key1 in self.matrix.keys():\n",
        "            tmp += str(key1) + \":\"\n",
        "            for key2 in self.matrix[key1]:\n",
        "                tmp += str(key2) + \"-\" + str(self.matrix[key1][key2]) + \",\"\n",
        "            tmp = tmp[:-1] + \"\\n\"\n",
        "        f.write(tmp[:-1])\n",
        "        f.close()\n",
        "        \n",
        "    def loadBackup(self):\n",
        "        f = open(\"backupFiles/SubstitutionMatrix.txt\", \"r\")\n",
        "        backup = (f.read()).split(';')\n",
        "        self.totalLetterTransitions = int(backup[0])\n",
        "        backup = backup[1].split(\"\\n\")\n",
        "        for entryStr in backup:\n",
        "            key1 = entryStr[0]\n",
        "            for entry in entryStr[2:].split(','):\n",
        "                key2 = entry[0]\n",
        "                self.matrix[key1][key2] = int(entry[2:])\n",
        "        f.close()\n",
        "    \"\"\"\n"
      ],
      "metadata": {
        "id": "bWIfBEgBB9Rh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo\n",
        "Extraktion der Variationen in Vornamen."
      ],
      "metadata": {
        "id": "3CyZwWA7CEVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# install and import Entrez and Medline first\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "try:\n",
        "    from Bio import Entrez, Medline\n",
        "except:\n",
        "    # One of these 2 lines should work\n",
        "    # !pip install Bio\n",
        "    install('Bio')\n",
        "from Bio import Entrez, Medline\n",
        "\n",
        "\n",
        "def getPapers(myQuery, maxPapers, myEmail=\"freytag64@gmail.com\"):\n",
        "    \"\"\"retrieves some Papers from Pubmed\n",
        "\n",
        "    Args:\n",
        "        myQuery (str): is the given Query \n",
        "        maxPapers (int): is a limit of the number of papers, which will be retrieved\n",
        "        myEmail (str, optional): an email. Defaults to \"freytag64@gmail.com\".\n",
        "\n",
        "    Returns:\n",
        "        list: papers as list of dictionarys containing abstract, authors, ...\n",
        "    \"\"\"\n",
        "    # Get articles from PubMed\n",
        "    Entrez.email = myEmail\n",
        "    record = Entrez.read(Entrez.esearch(db=\"pubmed\", term=myQuery, retmax=maxPapers))\n",
        "    idlist = record[\"IdList\"]\n",
        "    print(\"\\nThere are %d records for %s.\" % (len(idlist), myQuery.strip()))\n",
        "    records = Medline.parse(Entrez.efetch(db=\"pubmed\", id=idlist, rettype=\"medline\", retmode=\"text\"))\n",
        "    return list(records)\n",
        "\n",
        "\n",
        "def retrieveAllFirstNames(records):\n",
        "    \"\"\"takes list of papers (each is a dict) and extracts the first names as a combined list with a regular expression \n",
        "\n",
        "    Args:\n",
        "        records (list): list of papers\n",
        "\n",
        "    Returns:\n",
        "        list: list of first names as str's\n",
        "    \"\"\"\n",
        "    # retrieves first names from authors with regular expressions\n",
        "    firstNameList = list()\n",
        "    for record in filter(lambda x: 'FAU' in x, records):\n",
        "        for fullName in record['FAU']:\n",
        "            # since names are formatted like 'Lastname, Firstnames', split by ',' to get Firstnames\n",
        "            firstName = fullName.split(',')[1].strip()\n",
        "            names1 = list(filter(lambda x: len(x) > 1, firstName.split()))\n",
        "            firstNameList.extend(names1)\n",
        "            # print(fullName + \" --> \" + str(names1))\n",
        "            \n",
        "            # fixed: does not get name-pairs like \"le Roux, Marlene F\", since the lastname 'Roux' starts with ' ' too\n",
        "            # fixed (see comment): does not really get name-pairs like \"Something, A Mohammed\", since A is just a single letter (it ignores A as a firstname)\n",
        "            # a better one can be generated by using Multiple Sequence Alignment from the lectures. Names like Al-Abehd with '-' are just added as 'Al-Abehd' too.\n",
        "            # sometimes accepts stuff like 'jr'\n",
        "            \n",
        "            \"\"\"\n",
        "            expression = r' ([a-zA-Z_-][a-zA-Z_-]+)'\n",
        "            names2 = re.findall(expression, fullName)\n",
        "            # firstNameList.extend(names2)            \n",
        "            \n",
        "            if names1 != names2:\n",
        "              print(fullName + \" --> \" + str(names1))\n",
        "              print(fullName + \" --> \" + str(names2))\n",
        "            \"\"\"\n",
        "\n",
        "    return firstNameList\n",
        "\n",
        "\n",
        "\n",
        "# TODO: test for bugs with test-cases (highly encouraged!)\n",
        "if __name__ == \"__main__\":\n",
        "    maxPapers = 60  # limit the number of papers retrieved\n",
        "\n",
        "    # Alternative: Save everything in a single tree --> then use \"tree=RadixTree()\"\n",
        "    tree = RadixTreesByWordLength()  # saves names in radix-trees. One for each word-length\n",
        "\n",
        "    matrix = SubstitutionMatrix()  # saves letter-transitions in a matrix\n",
        "\n",
        "    myQuery = \"(\\\"2021/01/20\\\"[Date - Publication] : \\\"2021/01/20\\\"[Date - Publication])\"\n",
        "    records = getPapers(myQuery, maxPapers)\n",
        "\n",
        "    firstnames = retrieveAllFirstNames(records)\n",
        "\n",
        "    for name in firstnames:\n",
        "        name = str(name).lower()\n",
        "\n",
        "        tree.insertWord(name)\n",
        "\n",
        "        # very simple function to get similar names (names of same length and only limited letter-substitutions).\n",
        "        # TODO: method of getting similar names sucks. A better way would be, for example, a Levensthein-like method that weigths substitutions less if they are likely in our substitution-matrix\n",
        "        maximumOfSubsitutions = 1\n",
        "        similarNames = tree.getSimilarWordsOfSameLength(maximumOfSubsitutions, name)\n",
        "        similarNames.remove(name)\n",
        "        if similarNames != []:\n",
        "            print(name + \" --> \" + similarNames.__str__())\n",
        "\n",
        "        matrix.addLetterVariationsToMatrix(name,\n",
        "                                           similarNames)  # this function is a bit redundant, since the getSimilarWordsOfSameLength-method could do the job too, but easier to read\n",
        "\n",
        "    print(tree)\n",
        "    print(matrix)\n",
        "\n",
        "# here is a possible way for looping over a lot of papers\n",
        "\"\"\"\n",
        "maxPapers = 100 #limit the number of papers retrieved each loop\n",
        "year = \"2021\"\n",
        "daysOfMonth = {\"01\":31, \"02\":28, \"03\":31, \"04\":30, \"05\":31, \"06\":30, \"07\":31, \"08\":31, \"09\":30, \"10\":31, \"11\":30, \"12\":31}\n",
        "for month in daysOfMonth.keys():\n",
        "    for day in range(1, daysOfMonth[month] + 1):\n",
        "        #get Papers\n",
        "        myQuery = \"(\\\"\" + year + \"/\" + month + \"/\" + str(day) + \"\\\"[Date - Publication] : \\\"\" + year + \"/\" + month + \"/\" + str(day) + \"\\\"[Date - Publication])\"\n",
        "        records = getPapers(myQuery, maxPapers)\n",
        "\n",
        "        #...\n",
        "        \n",
        "        pass\n",
        "    pass\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t3WAzxEOCKvv",
        "outputId": "5c5ef472-8a0d-47ce-c2ce-4c96411250cd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "There are 60 records for (\"2021/01/20\"[Date - Publication] : \"2021/01/20\"[Date - Publication]).\n",
            "Deepika, Mln --> ['Mln']\n",
            "Tella, Sunitha --> ['Sunitha']\n",
            "Avvari, Srilekha --> ['Srilekha']\n",
            "Pratibha, Nallari --> ['Nallari']\n",
            "Ananthapur, Venkateshwari --> ['Venkateshwari']\n",
            "Daniels, Debora --> ['Debora']\n",
            "Salley, Brenda --> ['Brenda']\n",
            "Walker, Corinne --> ['Corinne']\n",
            "Bridges, Mindy --> ['Mindy']\n",
            "Celis-Aguilar, Erika Maria --> ['Erika', 'Maria']\n",
            "Medina-Cabrera, Cindy Anahi --> ['Cindy', 'Anahi']\n",
            "Torrontegui-Zazueta, Luis Alejandro --> ['Luis', 'Alejandro']\n",
            "Nunez-Millan, Blanca Xochitl --> ['Blanca', 'Xochitl']\n",
            "Castro-Borquez, Karla Mariana --> ['Karla', 'Mariana']\n",
            "Obeso-Pereda, Alejandra --> ['Alejandra']\n",
            "Garcia-Valle, Cesar Guillermo --> ['Cesar', 'Guillermo']\n",
            "Ochoa-Miranda, Carlos Andrey --> ['Carlos', 'Andrey']\n",
            "Afsahi, Afsoun --> ['Afsoun']\n",
            "Jeena, Jaya --> ['Jaya']\n",
            "Manhas, Sunita --> ['Sunita']\n",
            "Prasad, Rajendra --> ['Rajendra']\n",
            "Prasad, Suvarna --> ['Suvarna']\n",
            "Gupta, Rajendra --> ['Rajendra']\n",
            "Consigliere, Paolo --> ['Paolo']\n",
            "Bernasconi, Alessio --> ['Alessio']\n",
            "Dimock, Richard --> ['Richard']\n",
            "Narvani, A Ali --> ['Ali']\n",
            "Scott, Charles P R --> ['Charles']\n",
            "Dieguez, Tessly A --> ['Tessly']\n",
            "Deepak, Pratibha --> ['Pratibha']\n",
            "Gu, Siqi --> ['Siqi']\n",
            "Wildman, Jessica L --> ['Jessica']\n",
            "Bayly, Benjamin L --> ['Benjamin']\n",
            "Bierman, Karen L --> ['Karen']\n",
            "Jacobson, Linda --> ['Linda']\n",
            "Benes, Mario --> ['Mario']\n",
            "Pozo, Guillermo --> ['Guillermo']\n",
            "Abian, Maria --> ['Maria']\n",
            "Millera, Angela --> ['Angela']\n",
            "Bilbao, Rafael --> ['Rafael']\n",
            "Alzueta, Maria U --> ['Maria']\n",
            "Jalowska, Magdalena --> ['Magdalena']\n",
            "Gornowicz-Porowska, Justyna --> ['Justyna']\n",
            "Seraszek-Jaros, Agnieszka --> ['Agnieszka']\n",
            "Bowszyc-Dmochowska, Monika --> ['Monika']\n",
            "Kaczmarek, Elzbieta --> ['Elzbieta']\n",
            "Dmochowski, Marian --> ['Marian']\n",
            "Kaliyadan, Feroze --> ['Feroze']\n",
            "Jayasree, Puravoor --> ['Puravoor']\n",
            "Ashique, Karalikkattil T --> ['Karalikkattil']\n",
            "Beni, Stephanie --> ['Stephanie']\n",
            "Chroinin, Deirdre Ni --> ['Deirdre', 'Ni']\n",
            "Fletcher, Tim --> ['Tim']\n",
            "Makki, Daoud --> ['Daoud']\n",
            "Balbisi, Basel --> ['Basel']\n",
            "Arshad, Mohammed S --> ['Mohammed']\n",
            "Monga, Puneet --> ['Puneet']\n",
            "Bale, Steven --> ['Steven']\n",
            "Trail, Ian --> ['Ian']\n",
            "Walton, Michael --> ['Michael']\n",
            "Kopechek, Kyle J --> ['Kyle']\n",
            "Frantz, Travis L --> ['Travis']\n",
            "Everhart, Joshua S --> ['Joshua']\n",
            "Samade, Richard --> ['Richard']\n",
            "Bishop, Julie Y --> ['Julie']\n",
            "Neviaser, Andrew S --> ['Andrew']\n",
            "Cvetanovich, Gregory L --> ['Gregory']\n",
            "Zhang, Victoria Shu --> ['Victoria', 'Shu']\n",
            "King, Marissa D --> ['Marissa']\n",
            "Vijayashankar, Cuddalore Sadasivan --> ['Cuddalore', 'Sadasivan']\n",
            "Valooran, George Jose --> ['George', 'Jose']\n",
            "Oltean, Alina --> ['Alina']\n",
            "Taber, Larry A --> ['Larry']\n",
            "Sharma, Geetanjali --> ['Geetanjali']\n",
            "Prossnitz, Eric R --> ['Eric']\n",
            "Hatthakit, Urai --> ['Urai']\n",
            "Aryal, Kalpana Paudel --> ['Kalpana', 'Paudel']\n",
            "Timalsina, Rekha --> ['Rekha']\n",
            "Pham, Victor --> ['Victor']\n",
            "Marsden, Matthew D --> ['Matthew']\n",
            "Jyothi, C Cecilia Xavier --> ['Cecilia', 'Xavier']\n",
            "Bandyopadhyay, Debapriya --> ['Debapriya']\n",
            "Sahu, Suchanda --> ['Suchanda']\n",
            "Patro, Binod Kumar --> ['Binod', 'Kumar']\n",
            "Nayak, Saurav --> ['Saurav']\n",
            "Lai, Chun-Chieh --> ['Chun-Chieh']\n",
            "Chang, Chun-Hsiang --> ['Chun-Hsiang']\n",
            "Elebyary, Omnia --> ['Omnia']\n",
            "Barbour, Abdelahhad --> ['Abdelahhad']\n",
            "Fine, Noah --> ['Noah']\n",
            "Tenenbaum, Howard C --> ['Howard']\n",
            "Glogauer, Michael --> ['Michael']\n",
            "Gao, Duo --> ['Duo']\n",
            "Zhu, Qiuning --> ['Qiuning']\n",
            "Ruan, Jianqing --> ['Jianqing']\n",
            "Sun, Tao --> ['Tao']\n",
            "Han, Liang --> ['Liang']\n",
            "Naik, Viraj G --> ['Viraj']\n",
            "Kumar, Vikash --> ['Vikash']\n",
            "Bhasikuttan, Achikanath C --> ['Achikanath']\n",
            "Kadu, Kavita --> ['Kavita']\n",
            "Ramanan, Sutapa Roy --> ['Sutapa', 'Roy']\n",
            "Bhosle, Akhil A --> ['Akhil']\n",
            "Banerjee, Mainak --> ['Mainak']\n",
            "Chatterjee, Amrita --> ['Amrita']\n",
            "Wang, Jiang-Lin --> ['Jiang-Lin']\n",
            "Zhang, Lu --> ['Lu']\n",
            "Zhao, Mei-Jiao --> ['Mei-Jiao']\n",
            "Zhang, Tao --> ['Tao']\n",
            "Liu, Yi --> ['Yi']\n",
            "Jiang, Feng-Lei --> ['Feng-Lei']\n",
            "Fan, Nannan --> ['Nannan']\n",
            "Li, Ping --> ['Ping']\n",
            "Wu, Chuanchen --> ['Chuanchen']\n",
            "Wang, Xin --> ['Xin']\n",
            "Zhou, Yongqing --> ['Yongqing']\n",
            "Tang, Bo --> ['Bo']\n",
            "Wu, Xin --> ['Xin']\n",
            "Li, Haiyan --> ['Haiyan']\n",
            "Kwon, Tae-Jun --> ['Tae-Jun']\n",
            "Jang, Eunseo --> ['Eunseo']\n",
            "Lee, Da-Sol --> ['Da-Sol']\n",
            "Haque, Md Enamul --> ['Md', 'Enamul']\n",
            "Park, Rang-Woon --> ['Rang-Woon']\n",
            "Lee, Byungheon --> ['Byungheon']\n",
            "Lee, Sang Bong --> ['Sang', 'Bong']\n",
            "Kim, Dongkyu --> ['Dongkyu']\n",
            "Jeon, Yong-Hyun --> ['Yong-Hyun']\n",
            "Kim, Kil-Soo --> ['Kil-Soo']\n",
            "Kim, Sang Kyoon --> ['Sang', 'Kyoon']\n",
            "Jhan, Yong-Yu --> ['Yong-Yu']\n",
            "Palou Zuniga, Guillermo --> ['Guillermo']\n",
            "Singh, Kanwar Abhay --> ['Kanwar', 'Abhay']\n",
            "Gaharwar, Akhilesh K --> ['Akhilesh']\n",
            "Alge, Daniel L --> ['Daniel']\n",
            "Bishop, Corey J --> ['Corey']\n",
            "Nankali, Maryam --> ['Maryam']\n",
            "Einalou, Zahra --> ['Zahra']\n",
            "Asadnia, Mohsen --> ['Mohsen']\n",
            "Razmjou, Amir --> ['Amir']\n",
            "Juvekar, Vinayak --> ['Vinayak']\n",
            "Lim, Chang Su --> ['Chang', 'Su']\n",
            "Lee, Dong Joon --> ['Dong', 'Joon']\n",
            "Song, Deuk Hwa --> ['Deuk', 'Hwa']\n",
            "Noh, Choong-Kyun --> ['Choong-Kyun']\n",
            "Kang, Hyuk --> ['Hyuk']\n",
            "Shin, Sung Jae --> ['Sung', 'Jae']\n",
            "Kim, Hwan Myung --> ['Hwan', 'Myung']\n",
            "Chen, Cheng --> ['Cheng']\n",
            "Demir, Emrah --> ['Emrah']\n",
            "Huang, Yuan --> ['Yuan']\n",
            "Qiu, Rongzu --> ['Rongzu']\n",
            "Nguyen, Andrew M --> ['Andrew']\n",
            "Decker, Jenna A --> ['Jenna']\n",
            "Dupuis, Janae E --> ['Janae']\n",
            "Little, Ann A --> ['Ann']\n",
            "Ottenhoff, Lauren D --> ['Lauren']\n",
            "Rajajee, Venkatakrishna --> ['Venkatakrishna']\n",
            "Sheehan, Kyle M --> ['Kyle']\n",
            "Williamson, Craig A --> ['Craig']\n",
            "Guo, Peng --> ['Peng']\n",
            "Busatto, Sara --> ['Sara']\n",
            "Huang, Jing --> ['Jing']\n",
            "Morad, Golnaz --> ['Golnaz']\n",
            "Moses, Marsha A --> ['Marsha']\n",
            "Zhu, Hanqi --> ['Hanqi']\n",
            "Nesler, Christopher --> ['Christopher']\n",
            "Divekar, Nikhil --> ['Nikhil']\n",
            "Peddinti, Vamsi --> ['Vamsi']\n",
            "Gregg, Robert D --> ['Robert']\n",
            "Tabassam, Qudsia --> ['Qudsia']\n",
            "Mehmood, Tahir --> ['Tahir']\n",
            "Ahmed, Sibtain --> ['Sibtain']\n",
            "Saeed, Shagufta --> ['Shagufta']\n",
            "Raza, Abdul Rauf --> ['Abdul', 'Rauf']\n",
            "Anwar, Farooq --> ['Farooq']\n",
            "Shanafelt, Amy --> ['Amy']\n",
            "Sadeghzadeh, Claire --> ['Claire']\n",
            "Chapman, Leah --> ['Leah']\n",
            "De Marco, Molly --> ['Molly']\n",
            "Harnack, Lisa --> ['Lisa']\n",
            "Gust, Susan --> ['Susan']\n",
            "Jackson, Melvin --> ['Melvin']\n",
            "Caspi, Caitlin --> ['Caitlin']\n",
            "Ball, Philip --> ['Philip']\n",
            "Cakir Edis, Ebru --> ['Ebru']\n",
            "Mutlucan Eraslan, Renginar --> ['Renginar']\n",
            "Hatipoglu, Osman --> ['Osman']\n",
            "Li, Ying --> ['Ying']\n",
            "Shi, Zhifeng --> ['Zhifeng']\n",
            "Liang, Wenqing --> ['Wenqing']\n",
            "Ma, Jingli --> ['Jingli']\n",
            "Chen, Xu --> ['Xu']\n",
            "Wu, Di --> ['Di']\n",
            "Tian, Yongtao --> ['Yongtao']\n",
            "Li, Xinjian --> ['Xinjian']\n",
            "Shan, Chongxin --> ['Chongxin']\n",
            "Fang, Xiaosheng --> ['Xiaosheng']\n",
            "Viola, Ignazio Maria --> ['Ignazio', 'Maria']\n",
            "Peterson, Brian --> ['Brian']\n",
            "Pisetta, Gabriele --> ['Gabriele']\n",
            "Pavar, Geethanjali --> ['Geethanjali']\n",
            "Akhtar, Hibbah --> ['Hibbah']\n",
            "Menoloascina, Filippo --> ['Filippo']\n",
            "Mangano, Enzo --> ['Enzo']\n",
            "Dunn, Katherine E --> ['Katherine']\n",
            "Gabl, Roman --> ['Roman']\n",
            "Nila, Alex --> ['Alex']\n",
            "Molinari, Emanuela --> ['Emanuela']\n",
            "Cummins, Cathal --> ['Cathal']\n",
            "Thompson, Gerard --> ['Gerard']\n",
            "Lo, Tsz-Yan Milly --> ['Tsz-Yan', 'Milly']\n",
            "Denison, Fiona C --> ['Fiona']\n",
            "Digard, Paul --> ['Paul']\n",
            "Malik, Omair --> ['Omair']\n",
            "Dunn, Mark J G --> ['Mark']\n",
            "McDougall, Catherine M --> ['Catherine']\n",
            "Mehendale, Felicity V --> ['Felicity']\n",
            "Amani, Armaghan --> ['Armaghan']\n",
            "Fellers, Caitlin M --> ['Caitlin']\n",
            "Eyebe, Antoinette --> ['Antoinette']\n",
            "Hall, Alyssa --> ['Alyssa']\n",
            "Howard, Meredith L --> ['Meredith']\n",
            "Panhotra, Shivani --> ['Shivani']\n",
            "Khan, Sabina --> ['Sabina']\n",
            "Hassan, Mohammad Jaseem --> ['Mohammad', 'Jaseem']\n",
            "Jetley, Sujata --> ['Sujata']\n",
            "Gouda, Kalyani --> ['Kalyani']\n",
            "Das, Upasana --> ['Upasana']\n",
            "Dhangadamajhi, Gunanidhi --> ['Gunanidhi']\n",
            "Stewart, Julian M --> ['Julian']\n",
            "Pianosi, Paolo T --> ['Paolo']\n",
            "Song, Shu --> ['Shu']\n",
            "Gao, Ping --> ['Ping']\n",
            "Sun, Lin --> ['Lin']\n",
            "Kang, Dongwei --> ['Dongwei']\n",
            "Kongsted, Jacob --> ['Jacob']\n",
            "Poongavanam, Vasanthanathan --> ['Vasanthanathan']\n",
            "Zhan, Peng --> ['Peng']\n",
            "Liu, Xinyong --> ['Xinyong']\n",
            "Pavani, Giulia --> ['Giulia']\n",
            "Amendola, Mario --> ['Mario']\n",
            "Schutz, Narayan --> ['Narayan']\n",
            "Saner, Hugo --> ['Hugo']\n",
            "Botros, Angela --> ['Angela']\n",
            "Buluschek, Philipp --> ['Philipp']\n",
            "Urwyler, Prabitha --> ['Prabitha']\n",
            "Muri, Rene M --> ['Rene']\n",
            "Nef, Tobias --> ['Tobias']\n",
            "Litz, Brett T --> ['Brett']\n",
            "Cummings, Mackenzie H --> ['Mackenzie']\n",
            "Grunthal, Breanna --> ['Breanna']\n",
            "McLean, Caitlin L --> ['Caitlin']\n",
            "Hochachka, Wesley M --> ['Wesley']\n",
            "Alonso, Hany --> ['Hany']\n",
            "Gutierrez-Exposito, Carlos --> ['Carlos']\n",
            "Miller, Eliot --> ['Eliot']\n",
            "Johnston, Alison --> ['Alison']\n",
            "Li, Haifeng --> ['Haifeng']\n",
            "Zhang, Xinyu --> ['Xinyu']\n",
            "Wu, Yi --> ['Yi']\n",
            "Zhang, Feng --> ['Feng']\n",
            "Li, Chunlin --> ['Chunlin']\n",
            "Carvao, Joana --> ['Joana']\n",
            "Dinis-Ribeiro, Mario --> ['Mario']\n",
            "Pimentel-Nunes, Pedro --> ['Pedro']\n",
            "Libanio, Diogo --> ['Diogo']\n",
            "Xu, Yang --> ['Yang']\n",
            "Evans, Marie --> ['Marie']\n",
            "Soro, Marco --> ['Marco']\n",
            "Barany, Peter --> ['Peter']\n",
            "Carrero, Juan Jesus --> ['Juan', 'Jesus']\n",
            "Richards, Chloe B --> ['Chloe']\n",
            "Baumgarte, Thomas W --> ['Thomas']\n",
            "Shapiro, Stuart L --> ['Stuart']\n",
            "Jolayemi, Kelvin Olutimilehin --> ['Kelvin', 'Olutimilehin']\n",
            "Mamman, Mohammed --> ['Mohammed']\n",
            "Sani, Dahiru --> ['Dahiru']\n",
            "Okoronkwo, Magdalene Ogbonneya --> ['Magdalene', 'Ogbonneya']\n",
            "Udechukwu, Collins Chimezie --> ['Collins', 'Chimezie']\n",
            "Orakpoghenor, Ochuko --> ['Ochuko']\n",
            "Takabatake, Moe --> ['Moe']\n",
            "Hashimoto, Ayako --> ['Ayako']\n",
            "Chun, Wang-Jae --> ['Wang-Jae']\n",
            "Nambo, Masayuki --> ['Masayuki']\n",
            "Manaka, Yuichi --> ['Yuichi']\n",
            "Motokura, Ken --> ['Ken']\n",
            "Xia, Guang-Hui --> ['Guang-Hui']\n",
            "Li, Xin-Hua --> ['Xin-Hua']\n",
            "Zhang, Zhen --> ['Zhen']\n",
            "Jiang, Yu-Hang --> ['Yu-Hang']\n",
            "Mohamad, Yousef I --> ['Yousef']\n",
            "Baraheem, Samah S --> ['Samah']\n",
            "Nguyen, Tam V --> ['Tam']\n",
            "Bai, Dongsheng --> ['Dongsheng']\n",
            "Peng, Jinying --> ['Jinying']\n",
            "Yi, Chengqi --> ['Chengqi']\n",
            "cindy --> ['mindy']\n",
            "alejandra --> ['alejandro']\n",
            "mario --> ['maria', 'mario']\n",
            "maria --> ['mario', 'mario', 'maria', 'maria']\n",
            "angela --> ['angela']\n",
            "maria --> ['mario', 'mario', 'maria', 'maria', 'maria']\n",
            "andrew --> ['andrey', 'andrew']\n",
            "marissa --> ['marissa']\n",
            "matthew --> ['matthew']\n",
            "cecilia --> ['cecilia']\n",
            "saurav --> ['saurav']\n",
            "michael --> ['michael', 'michael']\n",
            "liang --> ['liang']\n",
            "sutapa --> ['sutapa']\n",
            "akhil --> ['akhil']\n",
            "mainak --> ['mainak']\n",
            "amrita --> ['amrita']\n",
            "tao --> ['tao']\n",
            "yi --> ['ni']\n",
            "sang --> ['sang']\n",
            "kyoon --> ['kyoon']\n",
            "abhay --> ['abhay']\n",
            "daniel --> ['daniel']\n",
            "corey --> ['corey']\n",
            "maryam --> ['maryam']\n",
            "mohsen --> ['mohsen']\n",
            "chang --> ['chang']\n",
            "su --> ['lu']\n",
            "dong --> ['bong']\n",
            "joon --> ['joon']\n",
            "sung --> ['sang', 'sang', 'sung']\n",
            "myung --> ['myung']\n",
            "cheng --> ['chang', 'chang', 'cheng']\n",
            "andrew --> ['andrey', 'andrew', 'andrew', 'andrew']\n",
            "janae --> ['janae']\n",
            "craig --> ['craig']\n",
            "peng --> ['ping']\n",
            "sara --> ['sara']\n",
            "jing --> ['ping', 'jing']\n",
            "marsha --> ['marsha']\n",
            "christopher --> ['christopher']\n",
            "robert --> ['robert']\n",
            "shagufta --> ['shagufta']\n",
            "abdul --> ['abdul']\n",
            "amy --> ['amy']\n",
            "molly --> ['molly']\n",
            "lisa --> ['lisa']\n",
            "melvin --> ['melvin']\n",
            "caitlin --> ['caitlin']\n",
            "philip --> ['philip']\n",
            "ying --> ['ping', 'jing', 'jing']\n",
            "xu --> ['lu', 'su']\n",
            "di --> ['ni', 'yi']\n",
            "maria --> ['mario', 'mario', 'maria', 'maria', 'maria', 'maria', 'maria']\n",
            "brian --> ['brian']\n",
            "hibbah --> ['hibbah']\n",
            "enzo --> ['enzo']\n",
            "cathal --> ['cathal']\n",
            "gerard --> ['gerard']\n",
            "milly --> ['molly', 'molly', 'milly']\n",
            "paul --> ['paul']\n",
            "omair --> ['omair']\n",
            "catherine --> ['katherine', 'catherine']\n",
            "caitlin --> ['caitlin', 'caitlin']\n",
            "antoinette --> ['antoinette']\n",
            "alyssa --> ['alyssa']\n",
            "meredith --> ['meredith']\n",
            "shivani --> ['shivani']\n",
            "sabina --> ['sabina']\n",
            "mohammad --> ['mohammed', 'mohammad']\n",
            "jaseem --> ['jaseem']\n",
            "sujata --> ['sujata']\n",
            "kalyani --> ['kalyani']\n",
            "julian --> ['julian']\n",
            "ping --> ['jing', 'jing', 'ying', 'peng', 'ping', 'ping']\n",
            "lin --> ['xin']\n",
            "dongwei --> ['dongwei']\n",
            "jacob --> ['jacob']\n",
            "peng --> ['ping', 'ping', 'ping', 'peng', 'peng']\n",
            "xinyong --> ['xinyong']\n",
            "giulia --> ['giulia']\n",
            "mario --> ['maria', 'mario', 'maria', 'maria', 'maria', 'maria', 'maria', 'mario', 'mario']\n",
            "hugo --> ['hugo']\n",
            "angela --> ['angela', 'angela', 'angela']\n",
            "prabitha --> ['prabitha']\n",
            "tobias --> ['tobias']\n",
            "brett --> ['brett']\n",
            "caitlin --> ['caitlin', 'caitlin', 'caitlin']\n",
            "hany --> ['hany']\n",
            "carlos --> ['carlos', 'carlos']\n",
            "eliot --> ['eliot']\n",
            "alison --> ['alison']\n",
            "yi --> ['ni', 'di']\n",
            "feng --> ['peng', 'peng', 'peng']\n",
            "chunlin --> ['chunlin']\n",
            "joana --> ['joana']\n",
            "mario --> ['maria', 'mario', 'maria', 'maria', 'maria', 'maria', 'maria', 'mario', 'mario', 'mario']\n",
            "yang --> ['sang', 'sang', 'ying', 'yang']\n",
            "marie --> ['maria', 'mario', 'mario', 'maria', 'maria', 'maria', 'maria', 'maria', 'mario', 'mario', 'mario', 'marie']\n",
            "marco --> ['mario', 'mario', 'mario', 'mario', 'mario', 'marco']\n",
            "peter --> ['peter']\n",
            "juan --> ['yuan', 'juan']\n",
            "jesus --> ['jesus']\n",
            "chloe --> ['chloe']\n",
            "thomas --> ['thomas']\n",
            "stuart --> ['stuart']\n",
            "kelvin --> ['melvin', 'melvin']\n",
            "mohammed --> ['mohammad', 'mohammad', 'mohammed', 'mohammed']\n",
            "dahiru --> ['dahiru']\n",
            "magdalene --> ['magdalena', 'magdalene']\n",
            "collins --> ['collins']\n",
            "ayako --> ['ayako']\n",
            "masayuki --> ['masayuki']\n",
            "guang-hui --> ['guang-hui']\n",
            "xin-hua --> ['xin-hua']\n",
            "tam --> ['tim', 'tao', 'tao', 'tam']\n",
            "jinying --> ['jinying']\n",
            "chengqi --> ['chengqi']\n",
            "RadixTree with words of length 2:\n",
            "bo.\n",
            "di.\n",
            "lu.\n",
            "md.\n",
            "ni.\n",
            "su.\n",
            "xu.\n",
            "yi.\n",
            "__.\n",
            "RadixTree with words of length 3:\n",
            "a\n",
            "_\n",
            "_li.\n",
            "_my.\n",
            "_nn.\n",
            "_my.\n",
            "duo.\n",
            "hwa.\n",
            "ian.\n",
            "jae.\n",
            "ken.\n",
            "lin.\n",
            "m\n",
            "_ln.\n",
            "_oe.\n",
            "roy.\n",
            "shu.\n",
            "___.\n",
            "t\n",
            "_\n",
            "_\n",
            "_ao.\n",
            "___.\n",
            "_im.\n",
            "_a\n",
            "__m.\n",
            "__o.\n",
            "_am.\n",
            "xin.\n",
            "___.\n",
            "RadixTree with words of length 4:\n",
            "a\n",
            "_lex.\n",
            "_mir.\n",
            "bong.\n",
            "d\n",
            "_euk.\n",
            "_ong.\n",
            "e\n",
            "_\n",
            "_bru.\n",
            "_nzo.\n",
            "_ric.\n",
            "_nzo.\n",
            "feng.\n",
            "h\n",
            "_\n",
            "_\n",
            "_ugo.\n",
            "_wan.\n",
            "_yuk.\n",
            "_any.\n",
            "_ugo.\n",
            "_any.\n",
            "j\n",
            "_\n",
            "_\n",
            "_\n",
            "_aya.\n",
            "_o\n",
            "__on.\n",
            "__se.\n",
            "_ing.\n",
            "_oon.\n",
            "_ing.\n",
            "_uan.\n",
            "_uan.\n",
            "kyle.\n",
            "____.\n",
            "l\n",
            "_\n",
            "_eah.\n",
            "_isa.\n",
            "_uis.\n",
            "_isa.\n",
            "mark.\n",
            "noah.\n",
            "p\n",
            "_\n",
            "_\n",
            "_\n",
            "_aul.\n",
            "_eng.\n",
            "_ing.\n",
            "_aul.\n",
            "_ing.\n",
            "_eng.\n",
            "_ing.\n",
            "_eng.\n",
            "r\n",
            "_auf.\n",
            "_ene.\n",
            "s\n",
            "_\n",
            "_\n",
            "_\n",
            "_ang.\n",
            "____.\n",
            "_iqi.\n",
            "_ang.\n",
            "_ung.\n",
            "_ara.\n",
            "_ung.\n",
            "_ara.\n",
            "urai.\n",
            "y\n",
            "_\n",
            "_ang.\n",
            "_ing.\n",
            "_uan.\n",
            "_ang.\n",
            "zhen.\n",
            "RadixTree with words of length 5:\n",
            "a\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_khil.\n",
            "_lina.\n",
            "_nahi.\n",
            "_bhay.\n",
            "_khil.\n",
            "_b\n",
            "__dul.\n",
            "__hay.\n",
            "_bdul.\n",
            "_yako.\n",
            "_yako.\n",
            "b\n",
            "_\n",
            "_\n",
            "_asel.\n",
            "_inod.\n",
            "_rian.\n",
            "_r\n",
            "__ett.\n",
            "__ian.\n",
            "_rett.\n",
            "c\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_esar.\n",
            "_indy.\n",
            "_orey.\n",
            "_hang.\n",
            "_orey.\n",
            "_h\n",
            "__ang.\n",
            "__eng.\n",
            "_heng.\n",
            "_raig.\n",
            "_hloe.\n",
            "_raig.\n",
            "_hloe.\n",
            "d\n",
            "_aoud.\n",
            "_iogo.\n",
            "e\n",
            "_\n",
            "_liot.\n",
            "_mrah.\n",
            "_rika.\n",
            "_liot.\n",
            "fiona.\n",
            "hanqi.\n",
            "j\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_anae.\n",
            "_enna.\n",
            "_ulie.\n",
            "_a\n",
            "__cob.\n",
            "__nae.\n",
            "_acob.\n",
            "_oana.\n",
            "_esus.\n",
            "_oana.\n",
            "_esus.\n",
            "k\n",
            "_\n",
            "_ar\n",
            "___en.\n",
            "___la.\n",
            "_umar.\n",
            "_yoon.\n",
            "_yoon.\n",
            "l\n",
            "_\n",
            "_arry.\n",
            "_i\n",
            "__ang.\n",
            "__nda.\n",
            "_iang.\n",
            "m\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_ari\n",
            "____a.\n",
            "____o.\n",
            "_indy.\n",
            "_ari\n",
            "____a.\n",
            "____o.\n",
            "_aria.\n",
            "_____.\n",
            "_aria.\n",
            "_yung.\n",
            "_olly.\n",
            "_yung.\n",
            "_aria.\n",
            "_olly.\n",
            "_aria.\n",
            "_illy.\n",
            "_ario.\n",
            "_illy.\n",
            "_ario.\n",
            "_____.\n",
            "_ari\n",
            "____e.\n",
            "____o.\n",
            "_ar\n",
            "___co.\n",
            "___ie.\n",
            "_arco.\n",
            "o\n",
            "_\n",
            "_m\n",
            "__air.\n",
            "__nia.\n",
            "_sman.\n",
            "_mair.\n",
            "p\n",
            "_\n",
            "_aolo.\n",
            "_____.\n",
            "_e\n",
            "__dro.\n",
            "__ter.\n",
            "_eter.\n",
            "r\n",
            "_ekha.\n",
            "_oman.\n",
            "s\n",
            "_amah.\n",
            "_usan.\n",
            "tahir.\n",
            "v\n",
            "_amsi.\n",
            "_iraj.\n",
            "xinyu.\n",
            "zahra.\n",
            "RadixTree with words of length 6:\n",
            "a\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_fsoun.\n",
            "_n\n",
            "__drey.\n",
            "__gela.\n",
            "_n\n",
            "__drew.\n",
            "__gela.\n",
            "_mrita.\n",
            "_ndrew.\n",
            "_mrita.\n",
            "_ndrew.\n",
            "_lyssa.\n",
            "_ndrew.\n",
            "_lyssa.\n",
            "_ngela.\n",
            "_lison.\n",
            "_ngela.\n",
            "_lison.\n",
            "b\n",
            "_lanca.\n",
            "_renda.\n",
            "c\n",
            "_\n",
            "_\n",
            "_a\n",
            "__rlos.\n",
            "__thal.\n",
            "_laire.\n",
            "_a\n",
            "__rlos.\n",
            "__thal.\n",
            "_arlos.\n",
            "d\n",
            "_\n",
            "_\n",
            "_a\n",
            "__-sol.\n",
            "__niel.\n",
            "_ebora.\n",
            "_a\n",
            "__hiru.\n",
            "__niel.\n",
            "_ahiru.\n",
            "e\n",
            "_namul.\n",
            "_unseo.\n",
            "f\n",
            "_arooq.\n",
            "_eroze.\n",
            "g\n",
            "_\n",
            "_\n",
            "_e\n",
            "__orge.\n",
            "__rard.\n",
            "_olnaz.\n",
            "_erard.\n",
            "_iulia.\n",
            "_iulia.\n",
            "h\n",
            "_\n",
            "_aiyan.\n",
            "_ibbah.\n",
            "_oward.\n",
            "_ibbah.\n",
            "j\n",
            "_\n",
            "_\n",
            "_aseem.\n",
            "_ingli.\n",
            "_oshua.\n",
            "_aseem.\n",
            "_ulian.\n",
            "_ulian.\n",
            "k\n",
            "_a\n",
            "__nwar.\n",
            "__vita.\n",
            "_elvin.\n",
            "lauren.\n",
            "m\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_a\n",
            "__inak.\n",
            "__rian.\n",
            "_onika.\n",
            "_a\n",
            "__inak.\n",
            "__ryam.\n",
            "_aryam.\n",
            "_ohsen.\n",
            "_arsha.\n",
            "_ohsen.\n",
            "_arsha.\n",
            "_elvin.\n",
            "_elvin.\n",
            "n\n",
            "_annan.\n",
            "_ikhil.\n",
            "ochuko.\n",
            "p\n",
            "_\n",
            "_audel.\n",
            "_hilip.\n",
            "_uneet.\n",
            "_hilip.\n",
            "qudsia.\n",
            "r\n",
            "_\n",
            "_afael.\n",
            "_o\n",
            "__bert.\n",
            "__ngzu.\n",
            "_obert.\n",
            "s\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_aurav.\n",
            "_teven.\n",
            "_unita.\n",
            "_aurav.\n",
            "_utapa.\n",
            "_abina.\n",
            "_utapa.\n",
            "_abina.\n",
            "_ujata.\n",
            "_tuart.\n",
            "_ujata.\n",
            "_tuart.\n",
            "t\n",
            "_\n",
            "_\n",
            "_essly.\n",
            "_obias.\n",
            "_ravis.\n",
            "_homas.\n",
            "_obias.\n",
            "_homas.\n",
            "vi\n",
            "__ctor.\n",
            "__kash.\n",
            "wesley.\n",
            "xavier.\n",
            "y\n",
            "_ousef.\n",
            "_uichi.\n",
            "RadixTree with words of length 7:\n",
            "alessio.\n",
            "breanna.\n",
            "c\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_ecilia.\n",
            "_harles.\n",
            "_orinne.\n",
            "_aitlin.\n",
            "_ecilia.\n",
            "_aitlin.\n",
            "_______.\n",
            "_aitlin.\n",
            "_______.\n",
            "_aitlin.\n",
            "_hunlin.\n",
            "_hunlin.\n",
            "_ollins.\n",
            "_hengqi.\n",
            "_ollins.\n",
            "_hengqi.\n",
            "d\n",
            "_\n",
            "_eirdre.\n",
            "_ong\n",
            "____kyu.\n",
            "____wei.\n",
            "_ongwei.\n",
            "filippo.\n",
            "gregory.\n",
            "haifeng.\n",
            "ignazio.\n",
            "j\n",
            "_\n",
            "_essica.\n",
            "_inying.\n",
            "_ustyna.\n",
            "_inying.\n",
            "k\n",
            "_\n",
            "_al\n",
            "___pana.\n",
            "___yani.\n",
            "_il-soo.\n",
            "_alyani.\n",
            "m\n",
            "_\n",
            "_\n",
            "_\n",
            "_ari\n",
            "____ana.\n",
            "____ssa.\n",
            "_ichael.\n",
            "_a\n",
            "__rissa.\n",
            "__tthew.\n",
            "_atthew.\n",
            "_ichael.\n",
            "_ichael.\n",
            "na\n",
            "__llari.\n",
            "__rayan.\n",
            "philipp.\n",
            "qiuning.\n",
            "richard.\n",
            "_______.\n",
            "s\n",
            "_\n",
            "_hivani.\n",
            "_ibtain.\n",
            "_u\n",
            "__nitha.\n",
            "__varna.\n",
            "_hivani.\n",
            "t\n",
            "_ae-jun.\n",
            "_sz-yan.\n",
            "upasana.\n",
            "vinayak.\n",
            "wenqing.\n",
            "x\n",
            "_\n",
            "_\n",
            "_in\n",
            "___jian.\n",
            "___yong.\n",
            "_ochitl.\n",
            "_in\n",
            "___-hua.\n",
            "___yong.\n",
            "_in-hua.\n",
            "y\n",
            "_ong\n",
            "____-yu.\n",
            "____tao.\n",
            "_u-hang.\n",
            "zhifeng.\n",
            "RadixTree with words of length 8:\n",
            "a\n",
            "_khilesh.\n",
            "_rmaghan.\n",
            "benjamin.\n",
            "ch\n",
            "__imezie.\n",
            "__ongxin.\n",
            "e\n",
            "_lzbieta.\n",
            "_manuela.\n",
            "fe\n",
            "__licity.\n",
            "__ng-lei.\n",
            "gabriele.\n",
            "jianqing.\n",
            "m\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_e\n",
            "__i-jiao.\n",
            "__redith.\n",
            "_ohammed.\n",
            "_eredith.\n",
            "_ohammad.\n",
            "_ohamm\n",
            "______ad.\n",
            "______ed.\n",
            "_asayuki.\n",
            "_ohammed.\n",
            "_asayuki.\n",
            "p\n",
            "_\n",
            "_ra\n",
            "___bitha.\n",
            "___tibha.\n",
            "_uravoor.\n",
            "_rabitha.\n",
            "r\n",
            "_ajendra.\n",
            "________.\n",
            "_enginar.\n",
            "s\n",
            "_\n",
            "_hagufta.\n",
            "_rilekha.\n",
            "_uchanda.\n",
            "_hagufta.\n",
            "victoria.\n",
            "wang-jae.\n",
            "yongqing.\n",
            "RadixTree with words of length 9:\n",
            "a\n",
            "_gnieszka.\n",
            "_lejandr\n",
            "________a.\n",
            "________o.\n",
            "byungheon.\n",
            "c\n",
            "_\n",
            "_atherine.\n",
            "_huanchen.\n",
            "_uddalore.\n",
            "_atherine.\n",
            "d\n",
            "_ebapriya.\n",
            "_ongsheng.\n",
            "gu\n",
            "__\n",
            "__ang-hui.\n",
            "__illermo.\n",
            "_________.\n",
            "_________.\n",
            "__nanidhi.\n",
            "__ang-hui.\n",
            "jiang-lin.\n",
            "katherine.\n",
            "ma\n",
            "__\n",
            "__ckenzie.\n",
            "__gdalen\n",
            "________a.\n",
            "________e.\n",
            "__gdalene.\n",
            "ogbonneya.\n",
            "rang-woon.\n",
            "s\n",
            "_adasivan.\n",
            "_tephanie.\n",
            "xiaosheng.\n",
            "yong-hyun.\n",
            "RadixTree with words of length 10:\n",
            "a\n",
            "_\n",
            "_bdelahhad.\n",
            "_chikanath.\n",
            "_ntoinette.\n",
            "_ntoinette.\n",
            "chun-chieh.\n",
            "geetanjali.\n",
            "RadixTree with words of length 11:\n",
            "ch\n",
            "__\n",
            "__oong-kyun.\n",
            "__ristopher.\n",
            "__un-hsiang.\n",
            "__ristopher.\n",
            "geethanjali.\n",
            "RadixTree with words of length 12:\n",
            "olutimilehin.\n",
            "RadixTree with words of length 13:\n",
            "karalikkattil.\n",
            "venkateshwari.\n",
            "RadixTree with words of length 14:\n",
            "v\n",
            "_asanthanathan.\n",
            "_enkatakrishna.\n",
            "\n",
            "Substitutionmatrix in %:\n",
            "\ta\tb\tc\td\te\tf\tg\th\ti\tj\tk\tl\tm\tn\to\tp\tq\tr\ts\tt\tu\tv\tw\tx\ty\tz\n",
            "a\t00.0\t00.0\t00.0\t00.0\t1.19\t00.0\t00.0\t00.0\t2.38\t00.0\t00.0\t00.0\t00.0\t00.0\t8.33\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "b\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "c\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t5.95\t00.0\t1.19\t00.0\t1.19\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "d\t00.0\t1.19\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t1.19\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t1.19\t00.0\n",
            "e\t13.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t4.76\t00.0\t00.0\t00.0\t00.0\t00.0\t5.95\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "f\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t3.57\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "g\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "h\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "i\t00.0\t00.0\t00.0\t00.0\t1.19\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t2.38\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "j\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t1.19\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t1.19\t00.0\n",
            "k\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t2.38\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "l\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t1.19\t00.0\t00.0\n",
            "m\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t2.38\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "n\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "o\t15.4\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "p\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t2.38\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t1.19\t00.0\n",
            "q\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "r\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "s\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t1.19\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "t\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "u\t2.38\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "v\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "w\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t2.38\t00.0\n",
            "x\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t1.19\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t1.19\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "y\t00.0\t00.0\t00.0\t1.19\t00.0\t00.0\t00.0\t00.0\t00.0\t2.38\t00.0\t00.0\t00.0\t2.38\t00.0\t1.19\t00.0\t00.0\t2.38\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "z\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmaxPapers = 100 #limit the number of papers retrieved each loop\\nyear = \"2021\"\\ndaysOfMonth = {\"01\":31, \"02\":28, \"03\":31, \"04\":30, \"05\":31, \"06\":30, \"07\":31, \"08\":31, \"09\":30, \"10\":31, \"11\":30, \"12\":31}\\nfor month in daysOfMonth.keys():\\n    for day in range(1, daysOfMonth[month] + 1):\\n        #get Papers\\n        myQuery = \"(\"\" + year + \"/\" + month + \"/\" + str(day) + \"\"[Date - Publication] : \"\" + year + \"/\" + month + \"/\" + str(day) + \"\"[Date - Publication])\"\\n        records = getPapers(myQuery, maxPapers)\\n\\n        #...\\n        \\n        pass\\n    pass\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}