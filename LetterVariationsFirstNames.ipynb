{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNixzaFFUKF5c1Z1veBJpg0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterNaggschga/Letter-Variations-in-First-Names-IS/blob/main/LetterVariationsFirstNames.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RadixTree\n",
        "Implementation eines RadixTrees."
      ],
      "metadata": {
        "id": "sjY2oRI3_jVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RadixTree:\n",
        "    \"\"\"contains a dict, which links to multiple RadixTree's. The key to another tree is a str and\n",
        "    if a transition ends in a word, the isWord-variable is True\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, isWord=False, transitions=None):\n",
        "        if transitions is None:\n",
        "            transitions = dict()\n",
        "        self.isWord = isWord\n",
        "        self.transitions = transitions\n",
        "\n",
        "    def insertWord(self, word):\n",
        "        \"\"\"inserts a word into the tree\n",
        "\n",
        "        Args:\n",
        "            word (str): is the str, that gets inserted\n",
        "        \"\"\"\n",
        "        for i in range(0, len(word)):\n",
        "            # goes through 'tobi' with 'tobi', 'tob', 'to', 't'\n",
        "            possibleTransition = word[:len(word) - i]\n",
        "            if self.transitions.get(possibleTransition) is not None:\n",
        "                child = self.transitions.get(possibleTransition)\n",
        "                if possibleTransition == word:\n",
        "                    child.isWord = True\n",
        "                else:\n",
        "                    child.insertWord(word[len(possibleTransition):])\n",
        "\n",
        "            for key in self.transitions.keys():\n",
        "                if possibleTransition == key[:len(possibleTransition)]:\n",
        "                    child = self.transitions.pop(key)\n",
        "                    newDict = dict()\n",
        "                    newDict[key[len(possibleTransition):]] = child\n",
        "                    self.transitions[possibleTransition] = RadixTree(possibleTransition == word, newDict)\n",
        "                    if possibleTransition != word:\n",
        "                        self.transitions[possibleTransition].insertWord(word[len(possibleTransition):])\n",
        "                    return\n",
        "\n",
        "        self.transitions[word] = RadixTree(True, dict())\n",
        "\n",
        "    def __strRecursive__(self, timesOfIndentation, lengthOfTransitionString):\n",
        "        result = \"\"\n",
        "        if self.isWord:\n",
        "            result += \".\"\n",
        "        keys = list(self.transitions.keys())\n",
        "        keys.sort()\n",
        "        for key in keys:\n",
        "            recursiveResult = self.transitions[key].__strRecursive__(timesOfIndentation + lengthOfTransitionString,\n",
        "                                                                     len(key))\n",
        "            result += \"\\n\" + (timesOfIndentation + lengthOfTransitionString) * \"_\" + key + recursiveResult\n",
        "        return result\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"generates a readable str, containing all class variables (the tree).\n",
        "\n",
        "        Returns:\n",
        "            str: the generated str\n",
        "        \"\"\"\n",
        "        return self.__strRecursive__(0, 0)\n",
        "\n",
        "    def getSimilarWordsOfSameLength(self, maximumDifferentLetters, word):\n",
        "        \"\"\"compares the given word with entries of the same length. Returns all of them with less or equal different letters than with maximumDifferentLetters described\n",
        "\n",
        "        Args:\n",
        "            maximumDifferentLetters (int): limits the amount of accepted different letters when comparing 2 words\n",
        "            word (str): the given word\n",
        "\n",
        "        Returns:\n",
        "            list: returns a list of similar words with the same length. Does contain itself\n",
        "        \"\"\"\n",
        "        if word == \"\":\n",
        "            return [word] if self.isWord else []\n",
        "\n",
        "        resultList = list()\n",
        "        for key in self.transitions.keys():\n",
        "            if len(key) > len(word):\n",
        "                continue\n",
        "            differences = 0\n",
        "            for i in range(0, len(key)):\n",
        "                differences += word[i] != key[i]\n",
        "                if differences > maximumDifferentLetters:\n",
        "                    break\n",
        "\n",
        "            if differences > maximumDifferentLetters:\n",
        "                continue\n",
        "            resultTmp = self.transitions[key].getSimilarWordsOfSameLength(maximumDifferentLetters - differences,\n",
        "                                                                          word[len(key):])\n",
        "            if resultTmp:\n",
        "                resultList.extend([key + tmp for tmp in resultTmp])\n",
        "        return resultList\n"
      ],
      "metadata": {
        "id": "dYT__cinAe6A"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RadixTreesByWordLength\n",
        "Ein Container, der Wörter je nach Länge in unterschiedliche RadixTrees ablegt und ansonsten wie ein Tree agiert."
      ],
      "metadata": {
        "id": "Gs-NXTuf_kfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RadixTreesByWordLength:\n",
        "    \"\"\"contains a dict, which links to multiple RadixTree's, each storing words of the same length\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.radixTrees = dict()\n",
        "\n",
        "    def insertWord(self, word):\n",
        "        \"\"\"inserts a word into the tree\n",
        "\n",
        "        Args:\n",
        "            word (str): is the str, that gets inserted\n",
        "        \"\"\"\n",
        "        length = len(word)\n",
        "        if self.radixTrees.get(length) is None:\n",
        "            self.radixTrees[length] = RadixTree()\n",
        "        self.radixTrees[length].insertWord(word)\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"generates a readable str, containing all class variables (the tree)\n",
        "\n",
        "        Returns:\n",
        "            str: the generated str\n",
        "        \"\"\"\n",
        "        tmp = \"\"\n",
        "        lengthStr = self.radixTrees.keys()\n",
        "        sortedLengths = [int(lengths) for lengths in lengthStr]\n",
        "        sortedLengths.sort()\n",
        "\n",
        "        for length in sortedLengths:\n",
        "            tmp += \"RadixTree with words of length \" + str(length) + \":\"\n",
        "            tmp += self.radixTrees[length].__str__()\n",
        "            tmp += \"\\n\"\n",
        "        return tmp\n",
        "\n",
        "    def getSimilarWordsOfSameLength(self, maximumDifferentLetters, word):\n",
        "        \"\"\"compares the given word with entries of the same length. Returns all of them with less or equal different letters than with maximumDifferentLetters described\n",
        "\n",
        "        Args:\n",
        "            maximumDifferentLetters (int): limits the amount of accepted different letters when comparing 2 words\n",
        "            word (str): the given word\n",
        "\n",
        "        Returns:\n",
        "            list: returns a list of similar words with the same length. Does contain itself\n",
        "        \"\"\"\n",
        "        length = len(word)\n",
        "        if self.radixTrees.get(length) is None:\n",
        "            return []\n",
        "        return self.radixTrees[length].getSimilarWordsOfSameLength(maximumDifferentLetters, word)\n"
      ],
      "metadata": {
        "id": "mIsL8VDqBM5m"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SubstituitionMatrix\n",
        "Implementation einer Substitutionsmatrix."
      ],
      "metadata": {
        "id": "SxfUiN4P_k7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SubstitutionMatrix:\n",
        "    \"\"\"Stores letter-variations as a matrix. The matrix is a dict linking the first letter to a second dict, linking the second letter to its occurrence (int)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.letters = [\n",
        "            'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u',\n",
        "            'v', 'w', 'x', 'y', 'z']\n",
        "        self.matrix = dict()\n",
        "        matrixTmp = dict()\n",
        "        for letter in self.letters:\n",
        "            self.matrix[letter] = dict()\n",
        "            matrixTmp[letter] = 0\n",
        "        for letter in self.letters:\n",
        "            self.matrix[letter] = matrixTmp.copy()\n",
        "        self.totalLetterTransitions = 0\n",
        "\n",
        "    def addLetterTransition(self, fr, to):\n",
        "        \"\"\"adds the transistion from one letter to another in the matrix\n",
        "\n",
        "        Args:\n",
        "            fr (str): a single lower character of the alphabet\n",
        "            to (str): a second single lower character of the alphabet\n",
        "\n",
        "        Returns:\n",
        "            bool: is False if one of the characters was not accepted, True if both were accepted\n",
        "        \"\"\"\n",
        "        if fr not in self.letters or to not in self.letters:\n",
        "            return False\n",
        "\n",
        "        self.matrix[fr][to] += 1\n",
        "        self.totalLetterTransitions += 1\n",
        "        return True\n",
        "\n",
        "    def getMatrixEntryInPercent(self, fr, to):\n",
        "        \"\"\"returns a specific matrix-entry in %\n",
        "\n",
        "        Args:\n",
        "            fr (str): a single lower character of the alphabet\n",
        "            to (str): a second single lower character of the alphabet\n",
        "\n",
        "        Returns:\n",
        "            float: returns -1.0 if one of the given str's was not accepted, the matrix-entry in percent otherwise\n",
        "        \"\"\"\n",
        "        if fr not in self.letters or to not in self.letters:\n",
        "            return -1.0\n",
        "\n",
        "        if self.totalLetterTransitions == 0:\n",
        "            return 0.0\n",
        "        return (self.matrix[fr][to] / self.totalLetterTransitions) * 100\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"generates a readable str for the matrix\n",
        "\n",
        "        Returns:\n",
        "            str: the generated str\n",
        "        \"\"\"\n",
        "\n",
        "        tmp = \"Substitutionmatrix in %:\\n\"\n",
        "        for to in self.matrix.keys():\n",
        "            tmp += \"\\t\" + to\n",
        "        tmp += \"\\n\"\n",
        "        \n",
        "        for fr in self.letters:\n",
        "            tmp += fr\n",
        "            for to in self.letters:\n",
        "                strEntry = str(self.getMatrixEntryInPercent(fr, to))\n",
        "                if len(strEntry) < 4:\n",
        "                    strEntry = (4 - len(strEntry)) * \"0\" + strEntry\n",
        "                tmp += \"\\t\" + strEntry[:4]\n",
        "            tmp += \"\\n\"\n",
        "        return tmp\n",
        "\n",
        "    def addLetterVariationsToMatrix(self, name, similarNames):\n",
        "        \"\"\"retrieves differences of names with the original and inserts these letter-variations into the substitution-matrix\n",
        "\n",
        "        Args:\n",
        "            name (str): is the original name\n",
        "            similarNames (list): list of similar names as str's\n",
        "        \"\"\"\n",
        "        for similarName in similarNames:\n",
        "            for i in range(len(name)):\n",
        "                if name[i] != similarName[i]:\n",
        "                    self.addLetterTransition(name[i], similarName[i])\n",
        "\n",
        "    # here is a simple way of storing and retrieveing the matrix in an external file\n",
        "    \"\"\"\n",
        "    def save(self):\n",
        "        f = open(\"backupFiles/SubstitutionMatrix.txt\", \"w\")\n",
        "        tmp = str(self.totalLetterTransitions) + \";\"\n",
        "        for key1 in self.matrix.keys():\n",
        "            tmp += str(key1) + \":\"\n",
        "            for key2 in self.matrix[key1]:\n",
        "                tmp += str(key2) + \"-\" + str(self.matrix[key1][key2]) + \",\"\n",
        "            tmp = tmp[:-1] + \"\\n\"\n",
        "        f.write(tmp[:-1])\n",
        "        f.close()\n",
        "        \n",
        "    def loadBackup(self):\n",
        "        f = open(\"backupFiles/SubstitutionMatrix.txt\", \"r\")\n",
        "        backup = (f.read()).split(';')\n",
        "        self.totalLetterTransitions = int(backup[0])\n",
        "        backup = backup[1].split(\"\\n\")\n",
        "        for entryStr in backup:\n",
        "            key1 = entryStr[0]\n",
        "            for entry in entryStr[2:].split(','):\n",
        "                key2 = entry[0]\n",
        "                self.matrix[key1][key2] = int(entry[2:])\n",
        "        f.close()\n",
        "    \"\"\"\n"
      ],
      "metadata": {
        "id": "bWIfBEgBB9Rh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo\n",
        "Extraktion der Variationen in Vornamen."
      ],
      "metadata": {
        "id": "3CyZwWA7CEVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# install and import Entrez and Medline first\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "try:\n",
        "    from Bio import Entrez, Medline\n",
        "except:\n",
        "    # One of these 2 lines should work\n",
        "    # !pip install Bio\n",
        "    install('Bio')\n",
        "from Bio import Entrez, Medline\n",
        "\n",
        "\n",
        "def getPapers(myQuery, maxPapers, myEmail=\"freytag64@gmail.com\"):\n",
        "    \"\"\"retrieves some Papers from Pubmed\n",
        "\n",
        "    Args:\n",
        "        myQuery (str): is the given Query \n",
        "        maxPapers (int): is a limit of the number of papers, which will be retrieved\n",
        "        myEmail (str, optional): an email. Defaults to \"freytag64@gmail.com\".\n",
        "\n",
        "    Returns:\n",
        "        list: papers as list of dictionarys containing abstract, authors, ...\n",
        "    \"\"\"\n",
        "    # Get articles from PubMed\n",
        "    Entrez.email = myEmail\n",
        "    record = Entrez.read(Entrez.esearch(db=\"pubmed\", term=myQuery, retmax=maxPapers))\n",
        "    idlist = record[\"IdList\"]\n",
        "    print(\"\\nThere are %d records for %s.\" % (len(idlist), myQuery.strip()))\n",
        "    records = Medline.parse(Entrez.efetch(db=\"pubmed\", id=idlist, rettype=\"medline\", retmode=\"text\"))\n",
        "    return list(records)\n",
        "\n",
        "\n",
        "def retrieveAllFirstNames(records):\n",
        "    \"\"\"takes list of papers (each is a dict) and extracts the first names as a combined list with a regular expression \n",
        "\n",
        "    Args:\n",
        "        records (list): list of papers\n",
        "\n",
        "    Returns:\n",
        "        list: list of first names as str's\n",
        "    \"\"\"\n",
        "    # retrieves first names from authors with regular expressions\n",
        "    firstNameList = list()\n",
        "    for record in filter(lambda x: 'FAU' in x, records):\n",
        "        for fullName in record['FAU']:\n",
        "            # TODO: does not get name-pairs like \"le Roux, Marlene F\", since the lastname 'Roux' starts with ' ' too\n",
        "            # TODO: does not really get name-pairs like \"Something, A Mohammed\", since A is just a single letter (it ignores A as a firstname)\n",
        "            # a better one can be generated by using Multiple Sequence Alignment from the lectures. Names like Al-Abehd with '-' are just added as 'Al-Abehd' too.\n",
        "            # sometimes accepts stuff like 'jr'\n",
        "            expression = r' ([a-zA-Z_-][a-zA-Z_-]+)'\n",
        "            names = re.findall(expression, fullName)\n",
        "            # print(fullName + \" --> \" + names.__str__())\n",
        "            firstNameList.extend(names)\n",
        "    return firstNameList\n",
        "\n",
        "\n",
        "# TODO: test for bugs with test-cases (highly encouraged!)\n",
        "if __name__ == \"__main__\":\n",
        "    maxPapers = 60  # limit the number of papers retrieved\n",
        "\n",
        "    # Alternative: Save everything in a single tree --> then use \"tree=RadixTree()\"\n",
        "    tree = RadixTreesByWordLength()  # saves names in radix-trees. One for each word-length\n",
        "\n",
        "    matrix = SubstitutionMatrix()  # saves letter-transitions in a matrix\n",
        "\n",
        "    myQuery = \"(\\\"2021/01/20\\\"[Date - Publication] : \\\"2021/01/20\\\"[Date - Publication])\"\n",
        "    records = getPapers(myQuery, maxPapers)\n",
        "\n",
        "    firstnames = retrieveAllFirstNames(records)\n",
        "\n",
        "    for name in firstnames:\n",
        "        name = str(name).lower()\n",
        "\n",
        "        tree.insertWord(name)\n",
        "\n",
        "        # very simple function to get similar names (names of same length and only limited letter-substitutions).\n",
        "        # TODO: method of getting similar names sucks. A better way would be, for example, a Levensthein-like method that weigths substitutions less if they are likely in our substitution-matrix\n",
        "        maximumOfSubsitutions = 1\n",
        "        similarNames = tree.getSimilarWordsOfSameLength(maximumOfSubsitutions, name)\n",
        "        similarNames.remove(name)\n",
        "        if similarNames != []:\n",
        "            print(name + \" --> \" + similarNames.__str__())\n",
        "\n",
        "        matrix.addLetterVariationsToMatrix(name,\n",
        "                                           similarNames)  # this function is a bit redundant, since the getSimilarWordsOfSameLength-method could do the job too, but easier to read\n",
        "\n",
        "    print(tree)\n",
        "    print(matrix)\n",
        "\n",
        "# here is a possible way for looping over a lot of papers\n",
        "\"\"\"\n",
        "maxPapers = 100 #limit the number of papers retrieved each loop\n",
        "year = \"2021\"\n",
        "daysOfMonth = {\"01\":31, \"02\":28, \"03\":31, \"04\":30, \"05\":31, \"06\":30, \"07\":31, \"08\":31, \"09\":30, \"10\":31, \"11\":30, \"12\":31}\n",
        "for month in daysOfMonth.keys():\n",
        "    for day in range(1, daysOfMonth[month] + 1):\n",
        "        #get Papers\n",
        "        myQuery = \"(\\\"\" + year + \"/\" + month + \"/\" + str(day) + \"\\\"[Date - Publication] : \\\"\" + year + \"/\" + month + \"/\" + str(day) + \"\\\"[Date - Publication])\"\n",
        "        records = getPapers(myQuery, maxPapers)\n",
        "\n",
        "        #...\n",
        "        \n",
        "        pass\n",
        "    pass\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t3WAzxEOCKvv",
        "outputId": "0ce834cd-2508-42a1-ffca-336fd78fc199"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "There are 60 records for (\"2021/01/20\"[Date - Publication] : \"2021/01/20\"[Date - Publication]).\n",
            "cindy --> ['mindy']\n",
            "alejandra --> ['alejandro']\n",
            "mario --> ['maria', 'mario']\n",
            "maria --> ['mario', 'mario', 'maria', 'maria']\n",
            "angela --> ['angela']\n",
            "maria --> ['mario', 'mario', 'maria', 'maria', 'maria']\n",
            "andrew --> ['andrey', 'andrew']\n",
            "marissa --> ['marissa']\n",
            "matthew --> ['matthew']\n",
            "cecilia --> ['cecilia']\n",
            "saurav --> ['saurav']\n",
            "michael --> ['michael', 'michael']\n",
            "liang --> ['liang']\n",
            "sutapa --> ['sutapa']\n",
            "akhil --> ['akhil']\n",
            "mainak --> ['mainak']\n",
            "amrita --> ['amrita']\n",
            "tao --> ['tao']\n",
            "yi --> ['ni']\n",
            "sang --> ['sang']\n",
            "kyoon --> ['kyoon']\n",
            "abhay --> ['abhay']\n",
            "daniel --> ['daniel']\n",
            "corey --> ['corey']\n",
            "maryam --> ['maryam']\n",
            "mohsen --> ['mohsen']\n",
            "chang --> ['chang']\n",
            "su --> ['lu']\n",
            "dong --> ['bong']\n",
            "joon --> ['joon']\n",
            "sung --> ['sang', 'sang', 'sung']\n",
            "myung --> ['myung']\n",
            "cheng --> ['chang', 'chang', 'cheng']\n",
            "andrew --> ['andrey', 'andrew', 'andrew', 'andrew']\n",
            "janae --> ['janae']\n",
            "craig --> ['craig']\n",
            "peng --> ['ping']\n",
            "sara --> ['sara']\n",
            "jing --> ['ping', 'jing']\n",
            "marsha --> ['marsha']\n",
            "christopher --> ['christopher']\n",
            "robert --> ['robert']\n",
            "shagufta --> ['shagufta']\n",
            "abdul --> ['abdul']\n",
            "amy --> ['amy']\n",
            "marco --> ['mario', 'mario', 'marco']\n",
            "molly --> ['molly']\n",
            "lisa --> ['lisa']\n",
            "melvin --> ['melvin']\n",
            "caitlin --> ['caitlin']\n",
            "philip --> ['philip']\n",
            "ebru --> ['ebru']\n",
            "ying --> ['ping', 'jing', 'jing']\n",
            "xu --> ['lu', 'su']\n",
            "di --> ['ni', 'yi']\n",
            "maria --> ['mario', 'mario', 'maria', 'maria', 'maria', 'maria', 'maria']\n",
            "brian --> ['brian']\n",
            "hibbah --> ['hibbah']\n",
            "enzo --> ['enzo']\n",
            "cathal --> ['cathal']\n",
            "gerard --> ['gerard']\n",
            "milly --> ['molly', 'molly', 'milly']\n",
            "paul --> ['paul']\n",
            "omair --> ['omair']\n",
            "catherine --> ['katherine', 'catherine']\n",
            "caitlin --> ['caitlin', 'caitlin']\n",
            "antoinette --> ['antoinette']\n",
            "alyssa --> ['alyssa']\n",
            "meredith --> ['meredith']\n",
            "shivani --> ['shivani']\n",
            "sabina --> ['sabina']\n",
            "mohammad --> ['mohammed', 'mohammad']\n",
            "jaseem --> ['jaseem']\n",
            "sujata --> ['sujata']\n",
            "kalyani --> ['kalyani']\n",
            "julian --> ['julian']\n",
            "ping --> ['jing', 'jing', 'ying', 'peng', 'ping', 'ping']\n",
            "lin --> ['xin']\n",
            "dongwei --> ['dongwei']\n",
            "jacob --> ['jacob']\n",
            "peng --> ['ping', 'ping', 'ping', 'peng', 'peng']\n",
            "xinyong --> ['xinyong']\n",
            "giulia --> ['giulia']\n",
            "mario --> ['maria', 'mario', 'maria', 'maria', 'maria', 'marco', 'marco', 'maria', 'maria', 'mario', 'mario']\n",
            "hugo --> ['hugo']\n",
            "angela --> ['angela', 'angela', 'angela']\n",
            "prabitha --> ['prabitha']\n",
            "tobias --> ['tobias']\n",
            "brett --> ['brett']\n",
            "caitlin --> ['caitlin', 'caitlin', 'caitlin']\n",
            "hany --> ['hany']\n",
            "carlos --> ['carlos', 'carlos']\n",
            "eliot --> ['eliot']\n",
            "alison --> ['alison']\n",
            "yi --> ['ni', 'di']\n",
            "feng --> ['peng', 'peng', 'peng']\n",
            "chunlin --> ['chunlin']\n",
            "joana --> ['joana']\n",
            "mario --> ['maria', 'mario', 'maria', 'maria', 'maria', 'marco', 'marco', 'maria', 'maria', 'mario', 'mario', 'mario']\n",
            "yang --> ['sang', 'sang', 'ying', 'yang']\n",
            "marie --> ['maria', 'mario', 'mario', 'maria', 'maria', 'maria', 'maria', 'maria', 'mario', 'mario', 'mario', 'marie']\n",
            "marco --> ['mario', 'mario', 'marco', 'mario', 'mario', 'mario', 'marco', 'marco']\n",
            "peter --> ['peter']\n",
            "juan --> ['yuan', 'juan']\n",
            "jesus --> ['jesus']\n",
            "chloe --> ['chloe']\n",
            "thomas --> ['thomas']\n",
            "stuart --> ['stuart']\n",
            "kelvin --> ['melvin', 'melvin']\n",
            "mohammed --> ['mohammad', 'mohammad', 'mohammed', 'mohammed']\n",
            "dahiru --> ['dahiru']\n",
            "magdalene --> ['magdalena', 'magdalene']\n",
            "collins --> ['collins']\n",
            "ayako --> ['ayako']\n",
            "masayuki --> ['masayuki']\n",
            "guang-hui --> ['guang-hui']\n",
            "xin-hua --> ['xin-hua']\n",
            "tam --> ['tim', 'tao', 'tao', 'tam']\n",
            "jinying --> ['jinying']\n",
            "chengqi --> ['chengqi']\n",
            "RadixTree with words of length 2:\n",
            "bo.\n",
            "di.\n",
            "lu.\n",
            "md.\n",
            "ni.\n",
            "su.\n",
            "xu.\n",
            "yi.\n",
            "__.\n",
            "RadixTree with words of length 3:\n",
            "a\n",
            "_\n",
            "_li.\n",
            "_my.\n",
            "_nn.\n",
            "_my.\n",
            "duo.\n",
            "hwa.\n",
            "ian.\n",
            "jae.\n",
            "ken.\n",
            "lin.\n",
            "m\n",
            "_ln.\n",
            "_oe.\n",
            "roy.\n",
            "shu.\n",
            "___.\n",
            "t\n",
            "_\n",
            "_\n",
            "_ao.\n",
            "___.\n",
            "_im.\n",
            "_a\n",
            "__m.\n",
            "__o.\n",
            "_am.\n",
            "xin.\n",
            "___.\n",
            "RadixTree with words of length 4:\n",
            "a\n",
            "_lex.\n",
            "_mir.\n",
            "bong.\n",
            "d\n",
            "_euk.\n",
            "_ong.\n",
            "e\n",
            "_\n",
            "_\n",
            "_bru.\n",
            "_dis.\n",
            "_ric.\n",
            "_bru.\n",
            "_nzo.\n",
            "_nzo.\n",
            "feng.\n",
            "h\n",
            "_\n",
            "_\n",
            "_ugo.\n",
            "_wan.\n",
            "_yuk.\n",
            "_any.\n",
            "_ugo.\n",
            "_any.\n",
            "j\n",
            "_\n",
            "_\n",
            "_\n",
            "_aya.\n",
            "_o\n",
            "__on.\n",
            "__se.\n",
            "_ing.\n",
            "_oon.\n",
            "_ing.\n",
            "_uan.\n",
            "_uan.\n",
            "kyle.\n",
            "____.\n",
            "l\n",
            "_\n",
            "_eah.\n",
            "_isa.\n",
            "_uis.\n",
            "_isa.\n",
            "mark.\n",
            "noah.\n",
            "p\n",
            "_\n",
            "_\n",
            "_\n",
            "_aul.\n",
            "_eng.\n",
            "_ing.\n",
            "_aul.\n",
            "_ing.\n",
            "_eng.\n",
            "_ing.\n",
            "_eng.\n",
            "r\n",
            "_auf.\n",
            "_ene.\n",
            "s\n",
            "_\n",
            "_\n",
            "_\n",
            "_ang.\n",
            "____.\n",
            "_iqi.\n",
            "_ang.\n",
            "_ung.\n",
            "_ara.\n",
            "_ung.\n",
            "_ara.\n",
            "urai.\n",
            "y\n",
            "_\n",
            "_ang.\n",
            "_ing.\n",
            "_uan.\n",
            "_ang.\n",
            "zhen.\n",
            "RadixTree with words of length 5:\n",
            "a\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_khil.\n",
            "_lina.\n",
            "_nahi.\n",
            "_bhay.\n",
            "_khil.\n",
            "_b\n",
            "__dul.\n",
            "__hay.\n",
            "_bdul.\n",
            "_yako.\n",
            "_yako.\n",
            "b\n",
            "_\n",
            "_\n",
            "_asel.\n",
            "_inod.\n",
            "_rian.\n",
            "_r\n",
            "__ett.\n",
            "__ian.\n",
            "_rett.\n",
            "c\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_esar.\n",
            "_indy.\n",
            "_orey.\n",
            "_hang.\n",
            "_orey.\n",
            "_h\n",
            "__ang.\n",
            "__eng.\n",
            "_heng.\n",
            "_raig.\n",
            "_hloe.\n",
            "_raig.\n",
            "_hloe.\n",
            "d\n",
            "_aoud.\n",
            "_iogo.\n",
            "e\n",
            "_\n",
            "_liot.\n",
            "_mrah.\n",
            "_rika.\n",
            "_liot.\n",
            "fiona.\n",
            "hanqi.\n",
            "j\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_anae.\n",
            "_enna.\n",
            "_ulie.\n",
            "_a\n",
            "__cob.\n",
            "__nae.\n",
            "_acob.\n",
            "_oana.\n",
            "_esus.\n",
            "_oana.\n",
            "_esus.\n",
            "k\n",
            "_\n",
            "_ar\n",
            "___en.\n",
            "___la.\n",
            "_umar.\n",
            "_yoon.\n",
            "_yoon.\n",
            "l\n",
            "_\n",
            "_arry.\n",
            "_i\n",
            "__ang.\n",
            "__nda.\n",
            "_iang.\n",
            "m\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_ari\n",
            "____a.\n",
            "____o.\n",
            "_indy.\n",
            "_ari\n",
            "____a.\n",
            "____o.\n",
            "_aria.\n",
            "_____.\n",
            "_aria.\n",
            "_yung.\n",
            "_arco.\n",
            "_yung.\n",
            "_arco.\n",
            "_olly.\n",
            "_aria.\n",
            "_olly.\n",
            "_aria.\n",
            "_illy.\n",
            "_ario.\n",
            "_illy.\n",
            "_ario.\n",
            "_____.\n",
            "_ari\n",
            "____e.\n",
            "____o.\n",
            "_ar\n",
            "___co.\n",
            "___ie.\n",
            "_arco.\n",
            "o\n",
            "_\n",
            "_m\n",
            "__air.\n",
            "__nia.\n",
            "_sman.\n",
            "_mair.\n",
            "p\n",
            "_\n",
            "_aolo.\n",
            "_____.\n",
            "_e\n",
            "__dro.\n",
            "__ter.\n",
            "_eter.\n",
            "r\n",
            "_ekha.\n",
            "_oman.\n",
            "s\n",
            "_amah.\n",
            "_usan.\n",
            "tahir.\n",
            "v\n",
            "_amsi.\n",
            "_iraj.\n",
            "xinyu.\n",
            "zahra.\n",
            "RadixTree with words of length 6:\n",
            "a\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_fsoun.\n",
            "_n\n",
            "__drey.\n",
            "__gela.\n",
            "_n\n",
            "__drew.\n",
            "__gela.\n",
            "_mrita.\n",
            "_ndrew.\n",
            "_mrita.\n",
            "_ndrew.\n",
            "_lyssa.\n",
            "_ndrew.\n",
            "_lyssa.\n",
            "_ngela.\n",
            "_lison.\n",
            "_ngela.\n",
            "_lison.\n",
            "b\n",
            "_lanca.\n",
            "_renda.\n",
            "c\n",
            "_\n",
            "_\n",
            "_a\n",
            "__rlos.\n",
            "__thal.\n",
            "_laire.\n",
            "_a\n",
            "__rlos.\n",
            "__thal.\n",
            "_arlos.\n",
            "d\n",
            "_\n",
            "_\n",
            "_a\n",
            "__-sol.\n",
            "__niel.\n",
            "_ebora.\n",
            "_a\n",
            "__hiru.\n",
            "__niel.\n",
            "_ahiru.\n",
            "e\n",
            "_namul.\n",
            "_unseo.\n",
            "f\n",
            "_arooq.\n",
            "_eroze.\n",
            "g\n",
            "_\n",
            "_\n",
            "_e\n",
            "__orge.\n",
            "__rard.\n",
            "_olnaz.\n",
            "_erard.\n",
            "_iulia.\n",
            "_iulia.\n",
            "h\n",
            "_\n",
            "_aiyan.\n",
            "_ibbah.\n",
            "_oward.\n",
            "_ibbah.\n",
            "j\n",
            "_\n",
            "_\n",
            "_aseem.\n",
            "_ingli.\n",
            "_oshua.\n",
            "_aseem.\n",
            "_ulian.\n",
            "_ulian.\n",
            "k\n",
            "_a\n",
            "__nwar.\n",
            "__vita.\n",
            "_elvin.\n",
            "lauren.\n",
            "m\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_a\n",
            "__inak.\n",
            "__rian.\n",
            "_onika.\n",
            "_a\n",
            "__inak.\n",
            "__ryam.\n",
            "_aryam.\n",
            "_ohsen.\n",
            "_arsha.\n",
            "_ohsen.\n",
            "_arsha.\n",
            "_elvin.\n",
            "_elvin.\n",
            "n\n",
            "_annan.\n",
            "_ikhil.\n",
            "ochuko.\n",
            "p\n",
            "_\n",
            "_audel.\n",
            "_hilip.\n",
            "_uneet.\n",
            "_hilip.\n",
            "qudsia.\n",
            "r\n",
            "_\n",
            "_afael.\n",
            "_o\n",
            "__bert.\n",
            "__ngzu.\n",
            "_obert.\n",
            "s\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_aurav.\n",
            "_teven.\n",
            "_unita.\n",
            "_aurav.\n",
            "_utapa.\n",
            "_abina.\n",
            "_utapa.\n",
            "_abina.\n",
            "_ujata.\n",
            "_tuart.\n",
            "_ujata.\n",
            "_tuart.\n",
            "t\n",
            "_\n",
            "_\n",
            "_essly.\n",
            "_obias.\n",
            "_ravis.\n",
            "_homas.\n",
            "_obias.\n",
            "_homas.\n",
            "vi\n",
            "__ctor.\n",
            "__kash.\n",
            "wesley.\n",
            "xavier.\n",
            "y\n",
            "_ousef.\n",
            "_uichi.\n",
            "zuniga.\n",
            "RadixTree with words of length 7:\n",
            "alessio.\n",
            "breanna.\n",
            "c\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_ecilia.\n",
            "_harles.\n",
            "_orinne.\n",
            "_aitlin.\n",
            "_ecilia.\n",
            "_aitlin.\n",
            "_______.\n",
            "_aitlin.\n",
            "_______.\n",
            "_aitlin.\n",
            "_hunlin.\n",
            "_hunlin.\n",
            "_ollins.\n",
            "_hengqi.\n",
            "_ollins.\n",
            "_hengqi.\n",
            "d\n",
            "_\n",
            "_eirdre.\n",
            "_ong\n",
            "____kyu.\n",
            "____wei.\n",
            "_ongwei.\n",
            "eraslan.\n",
            "filippo.\n",
            "gregory.\n",
            "haifeng.\n",
            "ignazio.\n",
            "j\n",
            "_\n",
            "_essica.\n",
            "_inying.\n",
            "_ustyna.\n",
            "_inying.\n",
            "k\n",
            "_\n",
            "_al\n",
            "___pana.\n",
            "___yani.\n",
            "_il-soo.\n",
            "_alyani.\n",
            "m\n",
            "_\n",
            "_\n",
            "_\n",
            "_ari\n",
            "____ana.\n",
            "____ssa.\n",
            "_ichael.\n",
            "_a\n",
            "__rissa.\n",
            "__tthew.\n",
            "_atthew.\n",
            "_ichael.\n",
            "_ichael.\n",
            "na\n",
            "__llari.\n",
            "__rayan.\n",
            "philipp.\n",
            "qiuning.\n",
            "richard.\n",
            "_______.\n",
            "s\n",
            "_\n",
            "_hivani.\n",
            "_ibtain.\n",
            "_u\n",
            "__nitha.\n",
            "__varna.\n",
            "_hivani.\n",
            "t\n",
            "_ae-jun.\n",
            "_sz-yan.\n",
            "upasana.\n",
            "vinayak.\n",
            "wenqing.\n",
            "x\n",
            "_\n",
            "_\n",
            "_in\n",
            "___jian.\n",
            "___yong.\n",
            "_ochitl.\n",
            "_in\n",
            "___-hua.\n",
            "___yong.\n",
            "_in-hua.\n",
            "y\n",
            "_ong\n",
            "____-yu.\n",
            "____tao.\n",
            "_u-hang.\n",
            "zhifeng.\n",
            "RadixTree with words of length 8:\n",
            "a\n",
            "_khilesh.\n",
            "_rmaghan.\n",
            "benjamin.\n",
            "ch\n",
            "__imezie.\n",
            "__ongxin.\n",
            "e\n",
            "_lzbieta.\n",
            "_manuela.\n",
            "fe\n",
            "__licity.\n",
            "__ng-lei.\n",
            "gabriele.\n",
            "jianqing.\n",
            "m\n",
            "_\n",
            "_\n",
            "_\n",
            "_\n",
            "_e\n",
            "__i-jiao.\n",
            "__redith.\n",
            "_ohammed.\n",
            "_eredith.\n",
            "_ohammad.\n",
            "_ohamm\n",
            "______ad.\n",
            "______ed.\n",
            "_asayuki.\n",
            "_ohammed.\n",
            "_asayuki.\n",
            "p\n",
            "_\n",
            "_ra\n",
            "___bitha.\n",
            "___tibha.\n",
            "_uravoor.\n",
            "_rabitha.\n",
            "r\n",
            "_ajendra.\n",
            "________.\n",
            "_enginar.\n",
            "s\n",
            "_\n",
            "_hagufta.\n",
            "_rilekha.\n",
            "_uchanda.\n",
            "_hagufta.\n",
            "victoria.\n",
            "wang-jae.\n",
            "yongqing.\n",
            "RadixTree with words of length 9:\n",
            "a\n",
            "_gnieszka.\n",
            "_lejandr\n",
            "________a.\n",
            "________o.\n",
            "byungheon.\n",
            "c\n",
            "_\n",
            "_atherine.\n",
            "_huanchen.\n",
            "_uddalore.\n",
            "_atherine.\n",
            "d\n",
            "_ebapriya.\n",
            "_ongsheng.\n",
            "gu\n",
            "__\n",
            "__ang-hui.\n",
            "__illermo.\n",
            "_________.\n",
            "_________.\n",
            "__nanidhi.\n",
            "__ang-hui.\n",
            "jiang-lin.\n",
            "katherine.\n",
            "ma\n",
            "__\n",
            "__ckenzie.\n",
            "__gdalen\n",
            "________a.\n",
            "________e.\n",
            "__gdalene.\n",
            "ogbonneya.\n",
            "rang-woon.\n",
            "s\n",
            "_adasivan.\n",
            "_tephanie.\n",
            "xiaosheng.\n",
            "yong-hyun.\n",
            "RadixTree with words of length 10:\n",
            "a\n",
            "_\n",
            "_bdelahhad.\n",
            "_chikanath.\n",
            "_ntoinette.\n",
            "_ntoinette.\n",
            "chun-chieh.\n",
            "geetanjali.\n",
            "RadixTree with words of length 11:\n",
            "ch\n",
            "__\n",
            "__oong-kyun.\n",
            "__ristopher.\n",
            "__un-hsiang.\n",
            "__ristopher.\n",
            "geethanjali.\n",
            "RadixTree with words of length 12:\n",
            "olutimilehin.\n",
            "RadixTree with words of length 13:\n",
            "karalikkattil.\n",
            "venkateshwari.\n",
            "RadixTree with words of length 14:\n",
            "v\n",
            "_asanthanathan.\n",
            "_enkatakrishna.\n",
            "\n",
            "Substitutionmatrix in %:\n",
            "\ta\tb\tc\td\te\tf\tg\th\ti\tj\tk\tl\tm\tn\to\tp\tq\tr\ts\tt\tu\tv\tw\tx\ty\tz\n",
            "a\t00.0\t00.0\t00.0\t00.0\t1.11\t00.0\t00.0\t00.0\t2.22\t00.0\t00.0\t00.0\t00.0\t00.0\t7.77\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "b\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "c\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t7.77\t00.0\t1.11\t00.0\t1.11\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "d\t00.0\t1.11\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t1.11\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t1.11\t00.0\n",
            "e\t12.2\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t4.44\t00.0\t00.0\t00.0\t00.0\t00.0\t5.55\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "f\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t3.33\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "g\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "h\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "i\t00.0\t00.0\t4.44\t00.0\t1.11\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t2.22\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "j\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t1.11\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t1.11\t00.0\n",
            "k\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t2.22\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "l\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t1.11\t00.0\t00.0\n",
            "m\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t2.22\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "n\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "o\t14.4\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "p\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t2.22\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t1.11\t00.0\n",
            "q\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "r\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "s\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t1.11\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "t\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "u\t2.22\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "v\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "w\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t2.22\t00.0\n",
            "x\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t1.11\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t1.11\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "y\t00.0\t00.0\t00.0\t1.11\t00.0\t00.0\t00.0\t00.0\t00.0\t2.22\t00.0\t00.0\t00.0\t2.22\t00.0\t1.11\t00.0\t00.0\t2.22\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "z\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\t00.0\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmaxPapers = 100 #limit the number of papers retrieved each loop\\nyear = \"2021\"\\ndaysOfMonth = {\"01\":31, \"02\":28, \"03\":31, \"04\":30, \"05\":31, \"06\":30, \"07\":31, \"08\":31, \"09\":30, \"10\":31, \"11\":30, \"12\":31}\\nfor month in daysOfMonth.keys():\\n    for day in range(1, daysOfMonth[month] + 1):\\n        #get Papers\\n        myQuery = \"(\"\" + year + \"/\" + month + \"/\" + str(day) + \"\"[Date - Publication] : \"\" + year + \"/\" + month + \"/\" + str(day) + \"\"[Date - Publication])\"\\n        records = getPapers(myQuery, maxPapers)\\n\\n        #...\\n        \\n        pass\\n    pass\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}